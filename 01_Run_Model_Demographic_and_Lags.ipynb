{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01 Run Model Demographic and Lags.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSCqMObaCJJeb1l1elwC23",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nateschor/Fantasy-Forecasting/blob/main/01_Run_Model_Demographic_and_Lags.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRaHEY2ReRO2"
      },
      "source": [
        "Package Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hR5r8Dpy8oa"
      },
      "source": [
        "Links: \n",
        "\n",
        "https://www.datagraphi.com/blog/post/2019/12/17/how-to-find-the-optimum-number-of-hidden-layers-and-nodes-in-a-neural-network-model\n",
        "\n",
        "https://www.tidyverse.org/blog/2020/02/slider-0-1-0/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCEEcGM_d3ju"
      },
      "source": [
        "import datetime\n",
        "from packaging import version\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhDpP9XXeJth"
      },
      "source": [
        "%matplotlib inline\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me6p9y55eZFO"
      },
      "source": [
        "Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01urGg4jeN6a"
      },
      "source": [
        "training = pd.read_csv(\"https://raw.githubusercontent.com/nateschor/Fantasy-Forecasting/main/data/intermediate/training_normalized_1961_to_2010.csv\")\n",
        "validation = pd.read_csv(\"https://raw.githubusercontent.com/nateschor/Fantasy-Forecasting/main/data/intermediate/validation_normalized_2011_to_2016.csv\")\n",
        "test = pd.read_csv(\"https://raw.githubusercontent.com/nateschor/Fantasy-Forecasting/main/data/intermediate/test_normalized_2017_to_2019.csv\")\n",
        "\n",
        "training[\"split\"] = \"Training\"\n",
        "validation[\"split\"] = \"Validation\"\n",
        "test[\"split\"] = \"Test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "mBQXfXPNe0l2",
        "outputId": "5c09fd93-6069-4d9e-f09d-bd49543e52c4"
      },
      "source": [
        "training"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>playerID</th>\n",
              "      <th>nameFirst</th>\n",
              "      <th>nameLast</th>\n",
              "      <th>yearID</th>\n",
              "      <th>teamID</th>\n",
              "      <th>Era</th>\n",
              "      <th>G</th>\n",
              "      <th>AB</th>\n",
              "      <th>Hits</th>\n",
              "      <th>Runs_Scored</th>\n",
              "      <th>Singles</th>\n",
              "      <th>Doubles</th>\n",
              "      <th>Triples</th>\n",
              "      <th>HR</th>\n",
              "      <th>TB</th>\n",
              "      <th>RBI</th>\n",
              "      <th>BB</th>\n",
              "      <th>K</th>\n",
              "      <th>HBP</th>\n",
              "      <th>Sacrifices</th>\n",
              "      <th>SB</th>\n",
              "      <th>CS</th>\n",
              "      <th>Points</th>\n",
              "      <th>birthMonth</th>\n",
              "      <th>birthCountry</th>\n",
              "      <th>birthState</th>\n",
              "      <th>birthCity</th>\n",
              "      <th>bats</th>\n",
              "      <th>throws</th>\n",
              "      <th>season_number</th>\n",
              "      <th>Points_last_season</th>\n",
              "      <th>Points_2_season</th>\n",
              "      <th>Points_3_season</th>\n",
              "      <th>birthYear</th>\n",
              "      <th>weight</th>\n",
              "      <th>height</th>\n",
              "      <th>Age</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aardsda01</td>\n",
              "      <td>David</td>\n",
              "      <td>Aardsma</td>\n",
              "      <td>2004</td>\n",
              "      <td>SFN</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Dec</td>\n",
              "      <td>USA</td>\n",
              "      <td>CO</td>\n",
              "      <td>Denver</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.419890</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.121951</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aardsda01</td>\n",
              "      <td>David</td>\n",
              "      <td>Aardsma</td>\n",
              "      <td>2006</td>\n",
              "      <td>CHN</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Dec</td>\n",
              "      <td>USA</td>\n",
              "      <td>CO</td>\n",
              "      <td>Denver</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.419890</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.170732</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aardsda01</td>\n",
              "      <td>David</td>\n",
              "      <td>Aardsma</td>\n",
              "      <td>2007</td>\n",
              "      <td>CHA</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Dec</td>\n",
              "      <td>USA</td>\n",
              "      <td>CO</td>\n",
              "      <td>Denver</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.419890</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.195122</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aardsda01</td>\n",
              "      <td>David</td>\n",
              "      <td>Aardsma</td>\n",
              "      <td>2008</td>\n",
              "      <td>BOS</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>Dec</td>\n",
              "      <td>USA</td>\n",
              "      <td>CO</td>\n",
              "      <td>Denver</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.419890</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.219512</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>aardsda01</td>\n",
              "      <td>David</td>\n",
              "      <td>Aardsma</td>\n",
              "      <td>2009</td>\n",
              "      <td>SEA</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Dec</td>\n",
              "      <td>USA</td>\n",
              "      <td>CO</td>\n",
              "      <td>Denver</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>5</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.419890</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.243902</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52938</th>\n",
              "      <td>zuvelpa01</td>\n",
              "      <td>Paul</td>\n",
              "      <td>Zuvella</td>\n",
              "      <td>1986</td>\n",
              "      <td>NYA</td>\n",
              "      <td>Free Agency</td>\n",
              "      <td>21</td>\n",
              "      <td>48</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Oct</td>\n",
              "      <td>USA</td>\n",
              "      <td>CA</td>\n",
              "      <td>San Mateo</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>5</td>\n",
              "      <td>171.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.187845</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.243902</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52939</th>\n",
              "      <td>zuvelpa01</td>\n",
              "      <td>Paul</td>\n",
              "      <td>Zuvella</td>\n",
              "      <td>1987</td>\n",
              "      <td>NYA</td>\n",
              "      <td>Free Agency</td>\n",
              "      <td>14</td>\n",
              "      <td>34</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Oct</td>\n",
              "      <td>USA</td>\n",
              "      <td>CA</td>\n",
              "      <td>San Mateo</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>6</td>\n",
              "      <td>21.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.187845</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.268293</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52940</th>\n",
              "      <td>zuvelpa01</td>\n",
              "      <td>Paul</td>\n",
              "      <td>Zuvella</td>\n",
              "      <td>1988</td>\n",
              "      <td>CLE</td>\n",
              "      <td>Free Agency</td>\n",
              "      <td>51</td>\n",
              "      <td>130</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>24</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>104.5</td>\n",
              "      <td>Oct</td>\n",
              "      <td>USA</td>\n",
              "      <td>CA</td>\n",
              "      <td>San Mateo</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>7</td>\n",
              "      <td>14.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.187845</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.292683</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52941</th>\n",
              "      <td>zuvelpa01</td>\n",
              "      <td>Paul</td>\n",
              "      <td>Zuvella</td>\n",
              "      <td>1989</td>\n",
              "      <td>CLE</td>\n",
              "      <td>Free Agency</td>\n",
              "      <td>24</td>\n",
              "      <td>58</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>59.5</td>\n",
              "      <td>Oct</td>\n",
              "      <td>USA</td>\n",
              "      <td>CA</td>\n",
              "      <td>San Mateo</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>8</td>\n",
              "      <td>104.5</td>\n",
              "      <td>14.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.187845</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.317073</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52942</th>\n",
              "      <td>zuvelpa01</td>\n",
              "      <td>Paul</td>\n",
              "      <td>Zuvella</td>\n",
              "      <td>1991</td>\n",
              "      <td>KCA</td>\n",
              "      <td>Free Agency</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Oct</td>\n",
              "      <td>USA</td>\n",
              "      <td>CA</td>\n",
              "      <td>San Mateo</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>9</td>\n",
              "      <td>59.5</td>\n",
              "      <td>104.5</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.187845</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.365854</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52943 rows × 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        playerID nameFirst nameLast  ...    height       Age     split\n",
              "0      aardsda01     David  Aardsma  ...  0.555556  0.121951  Training\n",
              "1      aardsda01     David  Aardsma  ...  0.555556  0.170732  Training\n",
              "2      aardsda01     David  Aardsma  ...  0.555556  0.195122  Training\n",
              "3      aardsda01     David  Aardsma  ...  0.555556  0.219512  Training\n",
              "4      aardsda01     David  Aardsma  ...  0.555556  0.243902  Training\n",
              "...          ...       ...      ...  ...       ...       ...       ...\n",
              "52938  zuvelpa01      Paul  Zuvella  ...  0.388889  0.243902  Training\n",
              "52939  zuvelpa01      Paul  Zuvella  ...  0.388889  0.268293  Training\n",
              "52940  zuvelpa01      Paul  Zuvella  ...  0.388889  0.292683  Training\n",
              "52941  zuvelpa01      Paul  Zuvella  ...  0.388889  0.317073  Training\n",
              "52942  zuvelpa01      Paul  Zuvella  ...  0.388889  0.365854  Training\n",
              "\n",
              "[52943 rows x 38 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "ccMHaNUwe0r9",
        "outputId": "9bee7819-ec1f-4d5c-c1c2-e8548ab13e7f"
      },
      "source": [
        "validation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>playerID</th>\n",
              "      <th>nameFirst</th>\n",
              "      <th>nameLast</th>\n",
              "      <th>yearID</th>\n",
              "      <th>teamID</th>\n",
              "      <th>Era</th>\n",
              "      <th>G</th>\n",
              "      <th>AB</th>\n",
              "      <th>Hits</th>\n",
              "      <th>Runs_Scored</th>\n",
              "      <th>Singles</th>\n",
              "      <th>Doubles</th>\n",
              "      <th>Triples</th>\n",
              "      <th>HR</th>\n",
              "      <th>TB</th>\n",
              "      <th>RBI</th>\n",
              "      <th>BB</th>\n",
              "      <th>K</th>\n",
              "      <th>HBP</th>\n",
              "      <th>Sacrifices</th>\n",
              "      <th>SB</th>\n",
              "      <th>CS</th>\n",
              "      <th>Points</th>\n",
              "      <th>birthMonth</th>\n",
              "      <th>birthCountry</th>\n",
              "      <th>birthState</th>\n",
              "      <th>birthCity</th>\n",
              "      <th>bats</th>\n",
              "      <th>throws</th>\n",
              "      <th>season_number</th>\n",
              "      <th>Points_last_season</th>\n",
              "      <th>Points_2_season</th>\n",
              "      <th>Points_3_season</th>\n",
              "      <th>birthYear</th>\n",
              "      <th>weight</th>\n",
              "      <th>height</th>\n",
              "      <th>Age</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aardsda01</td>\n",
              "      <td>David</td>\n",
              "      <td>Aardsma</td>\n",
              "      <td>2012</td>\n",
              "      <td>NYA</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Dec</td>\n",
              "      <td>USA</td>\n",
              "      <td>CO</td>\n",
              "      <td>Denver</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.419890</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.317073</td>\n",
              "      <td>Validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aardsda01</td>\n",
              "      <td>David</td>\n",
              "      <td>Aardsma</td>\n",
              "      <td>2013</td>\n",
              "      <td>NYN</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Dec</td>\n",
              "      <td>USA</td>\n",
              "      <td>CO</td>\n",
              "      <td>Denver</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.419890</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.341463</td>\n",
              "      <td>Validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aardsda01</td>\n",
              "      <td>David</td>\n",
              "      <td>Aardsma</td>\n",
              "      <td>2015</td>\n",
              "      <td>ATL</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>Dec</td>\n",
              "      <td>USA</td>\n",
              "      <td>CO</td>\n",
              "      <td>Denver</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.419890</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.390244</td>\n",
              "      <td>Validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abadfe01</td>\n",
              "      <td>Fernando</td>\n",
              "      <td>Abad</td>\n",
              "      <td>2011</td>\n",
              "      <td>HOU</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Dec</td>\n",
              "      <td>D.R.</td>\n",
              "      <td>La Romana</td>\n",
              "      <td>La Romana</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>2</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.940476</td>\n",
              "      <td>0.530387</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.195122</td>\n",
              "      <td>Validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abadfe01</td>\n",
              "      <td>Fernando</td>\n",
              "      <td>Abad</td>\n",
              "      <td>2012</td>\n",
              "      <td>HOU</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>37</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>Dec</td>\n",
              "      <td>D.R.</td>\n",
              "      <td>La Romana</td>\n",
              "      <td>La Romana</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.940476</td>\n",
              "      <td>0.530387</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.219512</td>\n",
              "      <td>Validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8600</th>\n",
              "      <td>zuninmi01</td>\n",
              "      <td>Mike</td>\n",
              "      <td>Zunino</td>\n",
              "      <td>2014</td>\n",
              "      <td>SEA</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>131</td>\n",
              "      <td>438</td>\n",
              "      <td>87</td>\n",
              "      <td>51</td>\n",
              "      <td>43</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>177</td>\n",
              "      <td>60</td>\n",
              "      <td>17</td>\n",
              "      <td>158</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>347.0</td>\n",
              "      <td>Mar</td>\n",
              "      <td>USA</td>\n",
              "      <td>FL</td>\n",
              "      <td>Cape Coral</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>2</td>\n",
              "      <td>139.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.011905</td>\n",
              "      <td>0.530387</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.121951</td>\n",
              "      <td>Validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8601</th>\n",
              "      <td>zuninmi01</td>\n",
              "      <td>Mike</td>\n",
              "      <td>Zunino</td>\n",
              "      <td>2015</td>\n",
              "      <td>SEA</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>112</td>\n",
              "      <td>350</td>\n",
              "      <td>61</td>\n",
              "      <td>28</td>\n",
              "      <td>39</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>105</td>\n",
              "      <td>28</td>\n",
              "      <td>21</td>\n",
              "      <td>132</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>183.0</td>\n",
              "      <td>Mar</td>\n",
              "      <td>USA</td>\n",
              "      <td>FL</td>\n",
              "      <td>Cape Coral</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>3</td>\n",
              "      <td>347.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.011905</td>\n",
              "      <td>0.530387</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.146341</td>\n",
              "      <td>Validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8602</th>\n",
              "      <td>zuninmi01</td>\n",
              "      <td>Mike</td>\n",
              "      <td>Zunino</td>\n",
              "      <td>2016</td>\n",
              "      <td>SEA</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>55</td>\n",
              "      <td>164</td>\n",
              "      <td>34</td>\n",
              "      <td>16</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>77</td>\n",
              "      <td>31</td>\n",
              "      <td>21</td>\n",
              "      <td>65</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>169.5</td>\n",
              "      <td>Mar</td>\n",
              "      <td>USA</td>\n",
              "      <td>FL</td>\n",
              "      <td>Cape Coral</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>4</td>\n",
              "      <td>183.0</td>\n",
              "      <td>347.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>1.011905</td>\n",
              "      <td>0.530387</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.170732</td>\n",
              "      <td>Validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8603</th>\n",
              "      <td>zychto01</td>\n",
              "      <td>Tony</td>\n",
              "      <td>Zych</td>\n",
              "      <td>2015</td>\n",
              "      <td>SEA</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Aug</td>\n",
              "      <td>USA</td>\n",
              "      <td>IL</td>\n",
              "      <td>Monee</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.281768</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.170732</td>\n",
              "      <td>Validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8604</th>\n",
              "      <td>zychto01</td>\n",
              "      <td>Tony</td>\n",
              "      <td>Zych</td>\n",
              "      <td>2016</td>\n",
              "      <td>SEA</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Aug</td>\n",
              "      <td>USA</td>\n",
              "      <td>IL</td>\n",
              "      <td>Monee</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.281768</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.195122</td>\n",
              "      <td>Validation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8605 rows × 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       playerID nameFirst nameLast  ...    height       Age       split\n",
              "0     aardsda01     David  Aardsma  ...  0.555556  0.317073  Validation\n",
              "1     aardsda01     David  Aardsma  ...  0.555556  0.341463  Validation\n",
              "2     aardsda01     David  Aardsma  ...  0.555556  0.390244  Validation\n",
              "3      abadfe01  Fernando     Abad  ...  0.500000  0.195122  Validation\n",
              "4      abadfe01  Fernando     Abad  ...  0.500000  0.219512  Validation\n",
              "...         ...       ...      ...  ...       ...       ...         ...\n",
              "8600  zuninmi01      Mike   Zunino  ...  0.500000  0.121951  Validation\n",
              "8601  zuninmi01      Mike   Zunino  ...  0.500000  0.146341  Validation\n",
              "8602  zuninmi01      Mike   Zunino  ...  0.500000  0.170732  Validation\n",
              "8603   zychto01      Tony     Zych  ...  0.555556  0.170732  Validation\n",
              "8604   zychto01      Tony     Zych  ...  0.555556  0.195122  Validation\n",
              "\n",
              "[8605 rows x 38 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "zUIIQi1xinrm",
        "outputId": "5a2b0461-ac36-4fb5-a0e1-caab57a18345"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>playerID</th>\n",
              "      <th>nameFirst</th>\n",
              "      <th>nameLast</th>\n",
              "      <th>yearID</th>\n",
              "      <th>teamID</th>\n",
              "      <th>Era</th>\n",
              "      <th>G</th>\n",
              "      <th>AB</th>\n",
              "      <th>Hits</th>\n",
              "      <th>Runs_Scored</th>\n",
              "      <th>Singles</th>\n",
              "      <th>Doubles</th>\n",
              "      <th>Triples</th>\n",
              "      <th>HR</th>\n",
              "      <th>TB</th>\n",
              "      <th>RBI</th>\n",
              "      <th>BB</th>\n",
              "      <th>K</th>\n",
              "      <th>HBP</th>\n",
              "      <th>Sacrifices</th>\n",
              "      <th>SB</th>\n",
              "      <th>CS</th>\n",
              "      <th>Points</th>\n",
              "      <th>birthMonth</th>\n",
              "      <th>birthCountry</th>\n",
              "      <th>birthState</th>\n",
              "      <th>birthCity</th>\n",
              "      <th>bats</th>\n",
              "      <th>throws</th>\n",
              "      <th>season_number</th>\n",
              "      <th>Points_last_season</th>\n",
              "      <th>Points_2_season</th>\n",
              "      <th>Points_3_season</th>\n",
              "      <th>birthYear</th>\n",
              "      <th>weight</th>\n",
              "      <th>height</th>\n",
              "      <th>Age</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abadfe01</td>\n",
              "      <td>Fernando</td>\n",
              "      <td>Abad</td>\n",
              "      <td>2017</td>\n",
              "      <td>BOS</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Dec</td>\n",
              "      <td>D.R.</td>\n",
              "      <td>La Romana</td>\n",
              "      <td>La Romana</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>9</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.940476</td>\n",
              "      <td>0.530387</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.341463</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abadfe01</td>\n",
              "      <td>Fernando</td>\n",
              "      <td>Abad</td>\n",
              "      <td>2019</td>\n",
              "      <td>SFN</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Dec</td>\n",
              "      <td>D.R.</td>\n",
              "      <td>La Romana</td>\n",
              "      <td>La Romana</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.940476</td>\n",
              "      <td>0.530387</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.390244</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abreubr01</td>\n",
              "      <td>Bryan</td>\n",
              "      <td>Abreu</td>\n",
              "      <td>2019</td>\n",
              "      <td>HOU</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Apr</td>\n",
              "      <td>D.R.</td>\n",
              "      <td>Distrito Nacional</td>\n",
              "      <td>Santo Domingo</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.083333</td>\n",
              "      <td>0.475138</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abreujo02</td>\n",
              "      <td>Jose</td>\n",
              "      <td>Abreu</td>\n",
              "      <td>2017</td>\n",
              "      <td>CHA</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>156</td>\n",
              "      <td>621</td>\n",
              "      <td>189</td>\n",
              "      <td>95</td>\n",
              "      <td>107</td>\n",
              "      <td>43</td>\n",
              "      <td>6</td>\n",
              "      <td>33</td>\n",
              "      <td>343</td>\n",
              "      <td>102</td>\n",
              "      <td>35</td>\n",
              "      <td>119</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>857.0</td>\n",
              "      <td>Jan</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>Cienfuegos</td>\n",
              "      <td>Cienfuegos</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>4</td>\n",
              "      <td>751.0</td>\n",
              "      <td>763.0</td>\n",
              "      <td>811.0</td>\n",
              "      <td>0.964286</td>\n",
              "      <td>0.613260</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.292683</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abreujo02</td>\n",
              "      <td>Jose</td>\n",
              "      <td>Abreu</td>\n",
              "      <td>2018</td>\n",
              "      <td>CHA</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>128</td>\n",
              "      <td>499</td>\n",
              "      <td>132</td>\n",
              "      <td>68</td>\n",
              "      <td>73</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>236</td>\n",
              "      <td>78</td>\n",
              "      <td>37</td>\n",
              "      <td>109</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>596.5</td>\n",
              "      <td>Jan</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>Cienfuegos</td>\n",
              "      <td>Cienfuegos</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>5</td>\n",
              "      <td>857.0</td>\n",
              "      <td>751.0</td>\n",
              "      <td>763.0</td>\n",
              "      <td>0.964286</td>\n",
              "      <td>0.613260</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.317073</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4589</th>\n",
              "      <td>zobribe01</td>\n",
              "      <td>Ben</td>\n",
              "      <td>Zobrist</td>\n",
              "      <td>2019</td>\n",
              "      <td>CHN</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>47</td>\n",
              "      <td>150</td>\n",
              "      <td>39</td>\n",
              "      <td>24</td>\n",
              "      <td>33</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>17</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>May</td>\n",
              "      <td>USA</td>\n",
              "      <td>IL</td>\n",
              "      <td>Eureka</td>\n",
              "      <td>B</td>\n",
              "      <td>R</td>\n",
              "      <td>15</td>\n",
              "      <td>594.5</td>\n",
              "      <td>470.0</td>\n",
              "      <td>739.5</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.392265</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.487805</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4590</th>\n",
              "      <td>zuninmi01</td>\n",
              "      <td>Mike</td>\n",
              "      <td>Zunino</td>\n",
              "      <td>2017</td>\n",
              "      <td>SEA</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>124</td>\n",
              "      <td>387</td>\n",
              "      <td>97</td>\n",
              "      <td>52</td>\n",
              "      <td>47</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>197</td>\n",
              "      <td>64</td>\n",
              "      <td>39</td>\n",
              "      <td>160</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>417.5</td>\n",
              "      <td>Mar</td>\n",
              "      <td>USA</td>\n",
              "      <td>FL</td>\n",
              "      <td>Cape Coral</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>5</td>\n",
              "      <td>169.5</td>\n",
              "      <td>183.0</td>\n",
              "      <td>347.0</td>\n",
              "      <td>1.011905</td>\n",
              "      <td>0.530387</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.195122</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4591</th>\n",
              "      <td>zuninmi01</td>\n",
              "      <td>Mike</td>\n",
              "      <td>Zunino</td>\n",
              "      <td>2018</td>\n",
              "      <td>SEA</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>113</td>\n",
              "      <td>373</td>\n",
              "      <td>75</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>153</td>\n",
              "      <td>44</td>\n",
              "      <td>24</td>\n",
              "      <td>150</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>278.5</td>\n",
              "      <td>Mar</td>\n",
              "      <td>USA</td>\n",
              "      <td>FL</td>\n",
              "      <td>Cape Coral</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>6</td>\n",
              "      <td>417.5</td>\n",
              "      <td>169.5</td>\n",
              "      <td>183.0</td>\n",
              "      <td>1.011905</td>\n",
              "      <td>0.530387</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.219512</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4592</th>\n",
              "      <td>zuninmi01</td>\n",
              "      <td>Mike</td>\n",
              "      <td>Zunino</td>\n",
              "      <td>2019</td>\n",
              "      <td>TBA</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>90</td>\n",
              "      <td>266</td>\n",
              "      <td>44</td>\n",
              "      <td>30</td>\n",
              "      <td>24</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>83</td>\n",
              "      <td>32</td>\n",
              "      <td>20</td>\n",
              "      <td>98</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>165.5</td>\n",
              "      <td>Mar</td>\n",
              "      <td>USA</td>\n",
              "      <td>FL</td>\n",
              "      <td>Cape Coral</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>7</td>\n",
              "      <td>278.5</td>\n",
              "      <td>417.5</td>\n",
              "      <td>169.5</td>\n",
              "      <td>1.011905</td>\n",
              "      <td>0.530387</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.243902</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4593</th>\n",
              "      <td>zychto01</td>\n",
              "      <td>Tony</td>\n",
              "      <td>Zych</td>\n",
              "      <td>2017</td>\n",
              "      <td>SEA</td>\n",
              "      <td>Long Ball</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Aug</td>\n",
              "      <td>USA</td>\n",
              "      <td>IL</td>\n",
              "      <td>Monee</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.281768</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.219512</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4594 rows × 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       playerID nameFirst nameLast  yearID  ...    weight    height       Age  split\n",
              "0      abadfe01  Fernando     Abad    2017  ...  0.530387  0.500000  0.341463   Test\n",
              "1      abadfe01  Fernando     Abad    2019  ...  0.530387  0.500000  0.390244   Test\n",
              "2     abreubr01     Bryan    Abreu    2019  ...  0.475138  0.444444  0.097561   Test\n",
              "3     abreujo02      Jose    Abreu    2017  ...  0.613260  0.555556  0.292683   Test\n",
              "4     abreujo02      Jose    Abreu    2018  ...  0.613260  0.555556  0.317073   Test\n",
              "...         ...       ...      ...     ...  ...       ...       ...       ...    ...\n",
              "4589  zobribe01       Ben  Zobrist    2019  ...  0.392265  0.555556  0.487805   Test\n",
              "4590  zuninmi01      Mike   Zunino    2017  ...  0.530387  0.500000  0.195122   Test\n",
              "4591  zuninmi01      Mike   Zunino    2018  ...  0.530387  0.500000  0.219512   Test\n",
              "4592  zuninmi01      Mike   Zunino    2019  ...  0.530387  0.500000  0.243902   Test\n",
              "4593   zychto01      Tony     Zych    2017  ...  0.281768  0.555556  0.219512   Test\n",
              "\n",
              "[4594 rows x 38 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irCNetVVlfWX"
      },
      "source": [
        "One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOrP32BIlj8N"
      },
      "source": [
        "all_data = pd.concat([training, validation, test])\n",
        "\n",
        "char_categorical_vars = [\"birthCountry\", \"birthState\", \"birthCity\", \"bats\", \"throws\", \"split\"] # \"playerID\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccCpKBOJwDZ5"
      },
      "source": [
        "all_dummies = pd.get_dummies(all_data[char_categorical_vars])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_09qYRql4Ov"
      },
      "source": [
        "def Perform_One_Hot_Encoding(dataset):\n",
        "\n",
        "  char_dummies = pd.get_dummies(dataset[char_categorical_vars])\n",
        "  birthMonth_dummies = pd.get_dummies(dataset[\"birthMonth\"])\n",
        "  season_number_dummies = pd.get_dummies(dataset[\"season_number\"])\n",
        "\n",
        "  return pd.concat([dataset.Points, dataset.Points_last_season, dataset.Points_2_season, dataset.Points_3_season, dataset.birthYear, dataset.weight, dataset.height, dataset.Age, char_dummies, birthMonth_dummies, season_number_dummies], axis=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySDn6xZpp-Cw"
      },
      "source": [
        "all_ready = Perform_One_Hot_Encoding(all_data)\n",
        "\n",
        "training_ready = all_ready[all_ready[\"split_Training\"] == 1]\n",
        "validation_ready = all_ready[all_ready[\"split_Validation\"] == 1]\n",
        "test_ready = all_ready[all_ready[\"split_Test\"] == 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "3CYmxrglsc0_",
        "outputId": "a1c4ffe2-80ac-464c-bbdc-4c377d2a496e"
      },
      "source": [
        "training_ready"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Points</th>\n",
              "      <th>Points_last_season</th>\n",
              "      <th>Points_2_season</th>\n",
              "      <th>Points_3_season</th>\n",
              "      <th>birthYear</th>\n",
              "      <th>weight</th>\n",
              "      <th>height</th>\n",
              "      <th>Age</th>\n",
              "      <th>birthCountry_Afghanistan</th>\n",
              "      <th>birthCountry_American Samoa</th>\n",
              "      <th>birthCountry_Aruba</th>\n",
              "      <th>birthCountry_Australia</th>\n",
              "      <th>birthCountry_Bahamas</th>\n",
              "      <th>birthCountry_Belgium</th>\n",
              "      <th>birthCountry_Belize</th>\n",
              "      <th>birthCountry_Brazil</th>\n",
              "      <th>birthCountry_CAN</th>\n",
              "      <th>birthCountry_Colombia</th>\n",
              "      <th>birthCountry_Cuba</th>\n",
              "      <th>birthCountry_Curacao</th>\n",
              "      <th>birthCountry_Czech Republic</th>\n",
              "      <th>birthCountry_D.R.</th>\n",
              "      <th>birthCountry_France</th>\n",
              "      <th>birthCountry_Germany</th>\n",
              "      <th>birthCountry_Guam</th>\n",
              "      <th>birthCountry_Honduras</th>\n",
              "      <th>birthCountry_Hong Kong</th>\n",
              "      <th>birthCountry_Indonesia</th>\n",
              "      <th>birthCountry_Italy</th>\n",
              "      <th>birthCountry_Jamaica</th>\n",
              "      <th>birthCountry_Japan</th>\n",
              "      <th>birthCountry_Lithuania</th>\n",
              "      <th>birthCountry_Mexico</th>\n",
              "      <th>birthCountry_Netherlands</th>\n",
              "      <th>birthCountry_Nicaragua</th>\n",
              "      <th>birthCountry_P.R.</th>\n",
              "      <th>birthCountry_Panama</th>\n",
              "      <th>birthCountry_Peru</th>\n",
              "      <th>birthCountry_Philippines</th>\n",
              "      <th>birthCountry_Poland</th>\n",
              "      <th>...</th>\n",
              "      <th>Aug</th>\n",
              "      <th>Dec</th>\n",
              "      <th>Feb</th>\n",
              "      <th>Jan</th>\n",
              "      <th>Jul</th>\n",
              "      <th>Jun</th>\n",
              "      <th>Mar</th>\n",
              "      <th>May</th>\n",
              "      <th>Nov</th>\n",
              "      <th>Oct</th>\n",
              "      <th>Sep</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.419890</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.121951</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.419890</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.170732</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.419890</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.195122</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.419890</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.219512</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.892857</td>\n",
              "      <td>0.419890</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.243902</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52938</th>\n",
              "      <td>21.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.187845</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.243902</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52939</th>\n",
              "      <td>14.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.187845</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.268293</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52940</th>\n",
              "      <td>104.5</td>\n",
              "      <td>14.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.187845</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.292683</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52941</th>\n",
              "      <td>59.5</td>\n",
              "      <td>104.5</td>\n",
              "      <td>14.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.187845</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.317073</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52942</th>\n",
              "      <td>0.0</td>\n",
              "      <td>59.5</td>\n",
              "      <td>104.5</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.187845</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.365854</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52943 rows × 3018 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Points  Points_last_season  Points_2_season  ...  27  28  29\n",
              "0         0.0                 0.0              0.0  ...   0   0   0\n",
              "1         0.5                 0.0              0.0  ...   0   0   0\n",
              "2         0.0                 0.5              0.0  ...   0   0   0\n",
              "3        -1.0                 0.0              0.5  ...   0   0   0\n",
              "4         0.0                -1.0              0.0  ...   0   0   0\n",
              "...       ...                 ...              ...  ...  ..  ..  ..\n",
              "52938    21.0               171.0             17.0  ...   0   0   0\n",
              "52939    14.0                21.0            171.0  ...   0   0   0\n",
              "52940   104.5                14.0             21.0  ...   0   0   0\n",
              "52941    59.5               104.5             14.0  ...   0   0   0\n",
              "52942     0.0                59.5            104.5  ...   0   0   0\n",
              "\n",
              "[52943 rows x 3018 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWIrBhJ0yXgn"
      },
      "source": [
        "Make sure no observations dropped"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC2h-9vkx5jh"
      },
      "source": [
        "assert training_ready.shape[0] == training.shape[0]\n",
        "assert validation_ready.shape[0] == validation.shape[0]\n",
        "assert test_ready.shape[0] == test.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyhJuCBiycoG"
      },
      "source": [
        "Make sure training, validation and test have same columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhnObG7Cyg-9"
      },
      "source": [
        "assert training_ready.shape[1] == validation_ready.shape[1]\n",
        "assert validation_ready.shape[1] == test_ready.shape[1]\n",
        "assert test_ready.shape[1] == training_ready.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQnOa7KkuhKA"
      },
      "source": [
        "training_x = training_ready.drop(\"Points\", axis = 1)\n",
        "training_y = training_ready[\"Points\"]\n",
        "val_x = validation_ready.drop(\"Points\", axis = 1)\n",
        "val_y = validation_ready[\"Points\"]\n",
        "test_x = test_ready.drop(\"Points\", axis = 1)\n",
        "test_y = test_ready[\"Points\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YajRyNzt8Yz"
      },
      "source": [
        "def Create_Num_Layers_And_Nodes(number_hidden_layers, number_input_nodes = training_x.shape[1], number_output_nodes = 1):\n",
        "\n",
        "  nodes_increment = np.geomspace(number_input_nodes, number_output_nodes, num = number_hidden_layers, dtype='int')\n",
        "  nodes_increment[0] = training_x.shape[1]\n",
        "  nodes_increment[-1] = 1\n",
        "  return nodes_increment.tolist()\n",
        "\n",
        "  # return np.floor(nodes_increment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-ZCVYzU2HOw"
      },
      "source": [
        "def Run_Model(hidden_layers_list):\n",
        "\n",
        "  hidden_layers_list = hidden_layers_list[0:len(hidden_layers_list) - 1]\n",
        "\n",
        "  model = models.Sequential()\n",
        "  for i in range(1, len(hidden_layers_list)):\n",
        "\n",
        "    if i == 1:\n",
        "      model.add(layers.Dense(hidden_layers_list[1], activation='selu',\n",
        "      input_shape=(training_x.shape[1],)))\n",
        "\n",
        "    else: \n",
        "      model.add(layers.Dense(hidden_layers_list[i], activation='selu'))\n",
        "      tf.keras.layers.Dropout(0.3)\n",
        "\n",
        "  model.add(layers.Dense(1)) \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt6yTP7szNsr"
      },
      "source": [
        "nodes_4_layers = [[training_x.shape[1], 1024, 256, 64, 32, 1],\n",
        "                  [training_x.shape[1], 2048, 256, 64, 32, 1],\n",
        "                  [training_x.shape[1], 1024, 128, 64, 32, 1],\n",
        "                  [training_x.shape[1], 256, 64, 32, 16, 1],\n",
        "                  [training_x.shape[1], 1024, 128, 64, 4, 1]]\n",
        "\n",
        "models_4_layers_list = [Run_Model(nodes_4_layers[i]) for i in range(0, len(nodes_4_layers))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbh1_hzI4Qhp"
      },
      "source": [
        "# models_list = [Run_Model(Create_Num_Layers_And_Nodes(num_layers)) for num_layers in range(6, 21)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Jsju4EuOtFG",
        "outputId": "b4f3b410-4714-495a-bfac-0ce6638ed0f2"
      },
      "source": [
        "models_list[-2].summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_143 (Dense)           (None, 1931)              5821965   \n",
            "                                                                 \n",
            " dense_144 (Dense)           (None, 1237)              2389884   \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 793)               981734    \n",
            "                                                                 \n",
            " dense_146 (Dense)           (None, 508)               403352    \n",
            "                                                                 \n",
            " dense_147 (Dense)           (None, 325)               165425    \n",
            "                                                                 \n",
            " dense_148 (Dense)           (None, 208)               67808     \n",
            "                                                                 \n",
            " dense_149 (Dense)           (None, 133)               27797     \n",
            "                                                                 \n",
            " dense_150 (Dense)           (None, 85)                11390     \n",
            "                                                                 \n",
            " dense_151 (Dense)           (None, 54)                4644      \n",
            "                                                                 \n",
            " dense_152 (Dense)           (None, 35)                1925      \n",
            "                                                                 \n",
            " dense_153 (Dense)           (None, 22)                792       \n",
            "                                                                 \n",
            " dense_154 (Dense)           (None, 14)                322       \n",
            "                                                                 \n",
            " dense_155 (Dense)           (None, 9)                 135       \n",
            "                                                                 \n",
            " dense_156 (Dense)           (None, 5)                 50        \n",
            "                                                                 \n",
            " dense_157 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            " dense_158 (Dense)           (None, 2)                 8         \n",
            "                                                                 \n",
            " dense_159 (Dense)           (None, 1)                 3         \n",
            "                                                                 \n",
            " dense_160 (Dense)           (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,877,254\n",
            "Trainable params: 9,877,254\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5OUoAsG6htD",
        "outputId": "f09674a9-5de2-4812-e8eb-aee22daaa2b2"
      },
      "source": [
        "# train_mse = []\n",
        "# val_mse = []\n",
        "# test_mse = []\n",
        "# for current_model in models_list:\n",
        "\n",
        "#   current_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4)\n",
        "#               ,loss=\"mean_squared_error\" # if we set from_logits=True we don not have specify a softmax activation function in the last layer\n",
        "#               ,metrics=['mean_squared_error'])\n",
        "  \n",
        "#   current_model.summary()\n",
        "\n",
        "#   history = current_model.fit(training_x, training_y ,\n",
        "#                       epochs = 200 ,validation_data=(val_x, val_y)\n",
        "#                       ,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_mean_squared_error', patience=2)]\n",
        "#                       )\n",
        "  \n",
        "#   index = np.where(history.history.get(\"val_mean_squared_error\") == np.min(history.history.get(\"val_mean_squared_error\")))[0][0]\n",
        "#   train_mse.append(history.history.get(\"mean_squared_error\")[index])\n",
        "#   val_mse.append(history.history.get(\"val_mean_squared_error\")[index])\n",
        "#   test_mse.append(current_model.evaluate(test_x, test_y)[1])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 607)               1830105   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 122)               74176     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 24)                2952      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 100       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,907,338\n",
            "Trainable params: 1,907,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1655/1655 [==============================] - 13s 7ms/step - loss: 56095.6484 - mean_squared_error: 56095.6484 - val_loss: 41387.9141 - val_mean_squared_error: 41387.9141\n",
            "Epoch 2/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 45109.5508 - mean_squared_error: 45109.5508 - val_loss: 40674.9414 - val_mean_squared_error: 40674.9414\n",
            "Epoch 3/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 40675.3008 - mean_squared_error: 40675.3008 - val_loss: 40856.7969 - val_mean_squared_error: 40856.7969\n",
            "Epoch 4/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 37712.5859 - mean_squared_error: 37712.5859 - val_loss: 41113.1523 - val_mean_squared_error: 41113.1523\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 46042.7266 - mean_squared_error: 46042.7266\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 793)               2390895   \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 208)               165152    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 54)                11286     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 14)                770       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 3)                 45        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,568,152\n",
            "Trainable params: 2,568,152\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1655/1655 [==============================] - 13s 7ms/step - loss: 54464.4648 - mean_squared_error: 54464.4648 - val_loss: 41656.5977 - val_mean_squared_error: 41656.5977\n",
            "Epoch 2/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 43199.6875 - mean_squared_error: 43199.6875 - val_loss: 41676.3242 - val_mean_squared_error: 41676.3242\n",
            "Epoch 3/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 38277.5469 - mean_squared_error: 38277.5469 - val_loss: 41672.2695 - val_mean_squared_error: 41672.2695\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 45906.7734 - mean_squared_error: 45906.7734\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 959)               2891385   \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 305)               292800    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 97)                29682     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 30)                2940      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 9)                 279       \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 3)                 30        \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,217,120\n",
            "Trainable params: 3,217,120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1655/1655 [==============================] - 13s 7ms/step - loss: 83971.9531 - mean_squared_error: 83971.9531 - val_loss: 64548.9727 - val_mean_squared_error: 64548.9727\n",
            "Epoch 2/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 83920.9297 - mean_squared_error: 83920.9297 - val_loss: 64507.0898 - val_mean_squared_error: 64507.0898\n",
            "Epoch 3/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 83870.2578 - mean_squared_error: 83870.2578 - val_loss: 64465.2930 - val_mean_squared_error: 64465.2930\n",
            "Epoch 4/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 83819.2500 - mean_squared_error: 83819.2500 - val_loss: 64423.3906 - val_mean_squared_error: 64423.3906\n",
            "Epoch 5/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 83768.4922 - mean_squared_error: 83768.4922 - val_loss: 64381.5742 - val_mean_squared_error: 64381.5742\n",
            "Epoch 6/200\n",
            "1655/1655 [==============================] - 12s 8ms/step - loss: 83717.6641 - mean_squared_error: 83717.6641 - val_loss: 64339.7773 - val_mean_squared_error: 64339.7773\n",
            "Epoch 7/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 83666.9062 - mean_squared_error: 83666.9062 - val_loss: 64298.0156 - val_mean_squared_error: 64298.0156\n",
            "Epoch 8/200\n",
            "1655/1655 [==============================] - 12s 8ms/step - loss: 83616.2031 - mean_squared_error: 83616.2031 - val_loss: 64256.3789 - val_mean_squared_error: 64256.3789\n",
            "Epoch 9/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 83565.7891 - mean_squared_error: 83565.7891 - val_loss: 64214.8711 - val_mean_squared_error: 64214.8711\n",
            "Epoch 10/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 83515.2422 - mean_squared_error: 83515.2422 - val_loss: 64173.2578 - val_mean_squared_error: 64173.2578\n",
            "Epoch 11/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 83464.8125 - mean_squared_error: 83464.8125 - val_loss: 64131.8906 - val_mean_squared_error: 64131.8906\n",
            "Epoch 12/200\n",
            "1655/1655 [==============================] - 12s 8ms/step - loss: 83414.4531 - mean_squared_error: 83414.4531 - val_loss: 64090.5391 - val_mean_squared_error: 64090.5391\n",
            "Epoch 13/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 83364.1016 - mean_squared_error: 83364.1016 - val_loss: 64049.1914 - val_mean_squared_error: 64049.1914\n",
            "Epoch 14/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 83313.8047 - mean_squared_error: 83313.8047 - val_loss: 64007.8320 - val_mean_squared_error: 64007.8320\n",
            "Epoch 15/200\n",
            "1655/1655 [==============================] - 12s 8ms/step - loss: 83263.5312 - mean_squared_error: 83263.5312 - val_loss: 63966.4570 - val_mean_squared_error: 63966.4570\n",
            "Epoch 16/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 83213.1953 - mean_squared_error: 83213.1953 - val_loss: 63925.2227 - val_mean_squared_error: 63925.2227\n",
            "Epoch 17/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 83163.1094 - mean_squared_error: 83163.1094 - val_loss: 63884.0938 - val_mean_squared_error: 63884.0938\n",
            "Epoch 18/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 83112.9062 - mean_squared_error: 83112.9062 - val_loss: 63843.0391 - val_mean_squared_error: 63843.0391\n",
            "Epoch 19/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 83062.8359 - mean_squared_error: 83062.8359 - val_loss: 63801.8398 - val_mean_squared_error: 63801.8398\n",
            "Epoch 20/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 83012.8438 - mean_squared_error: 83012.8438 - val_loss: 63760.8477 - val_mean_squared_error: 63760.8477\n",
            "Epoch 21/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 82962.8750 - mean_squared_error: 82962.8750 - val_loss: 63719.9258 - val_mean_squared_error: 63719.9258\n",
            "Epoch 22/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 82913.1953 - mean_squared_error: 82913.1953 - val_loss: 63679.0938 - val_mean_squared_error: 63679.0938\n",
            "Epoch 23/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 82863.3516 - mean_squared_error: 82863.3516 - val_loss: 63638.2461 - val_mean_squared_error: 63638.2461\n",
            "Epoch 24/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 82813.6016 - mean_squared_error: 82813.6016 - val_loss: 63597.4297 - val_mean_squared_error: 63597.4297\n",
            "Epoch 25/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 82763.7500 - mean_squared_error: 82763.7500 - val_loss: 63556.6406 - val_mean_squared_error: 63556.6406\n",
            "Epoch 26/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 82714.0312 - mean_squared_error: 82714.0312 - val_loss: 63516.2344 - val_mean_squared_error: 63516.2344\n",
            "Epoch 27/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 82664.3594 - mean_squared_error: 82664.3594 - val_loss: 63475.4844 - val_mean_squared_error: 63475.4844\n",
            "Epoch 28/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 82614.9609 - mean_squared_error: 82614.9609 - val_loss: 63435.0078 - val_mean_squared_error: 63435.0078\n",
            "Epoch 29/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 82565.4453 - mean_squared_error: 82565.4453 - val_loss: 63394.5039 - val_mean_squared_error: 63394.5039\n",
            "Epoch 30/200\n",
            "1655/1655 [==============================] - 12s 8ms/step - loss: 82516.0391 - mean_squared_error: 82516.0391 - val_loss: 63354.3789 - val_mean_squared_error: 63354.3789\n",
            "Epoch 31/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 82466.5234 - mean_squared_error: 82466.5234 - val_loss: 63313.5000 - val_mean_squared_error: 63313.5000\n",
            "Epoch 32/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 82417.0859 - mean_squared_error: 82417.0859 - val_loss: 63273.3594 - val_mean_squared_error: 63273.3594\n",
            "Epoch 33/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 82367.9141 - mean_squared_error: 82367.9141 - val_loss: 63233.2500 - val_mean_squared_error: 63233.2500\n",
            "Epoch 34/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 82318.8125 - mean_squared_error: 82318.8125 - val_loss: 63193.3711 - val_mean_squared_error: 63193.3711\n",
            "Epoch 35/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 82269.6250 - mean_squared_error: 82269.6250 - val_loss: 63153.0508 - val_mean_squared_error: 63153.0508\n",
            "Epoch 36/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 82220.5469 - mean_squared_error: 82220.5469 - val_loss: 63112.6641 - val_mean_squared_error: 63112.6641\n",
            "Epoch 37/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 82171.4609 - mean_squared_error: 82171.4609 - val_loss: 63072.6523 - val_mean_squared_error: 63072.6523\n",
            "Epoch 38/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 82122.6094 - mean_squared_error: 82122.6094 - val_loss: 63032.6523 - val_mean_squared_error: 63032.6523\n",
            "Epoch 39/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 82073.6328 - mean_squared_error: 82073.6328 - val_loss: 62993.0391 - val_mean_squared_error: 62993.0391\n",
            "Epoch 40/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 82024.7031 - mean_squared_error: 82024.7031 - val_loss: 62953.0195 - val_mean_squared_error: 62953.0195\n",
            "Epoch 41/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 81976.0156 - mean_squared_error: 81976.0156 - val_loss: 62913.2734 - val_mean_squared_error: 62913.2734\n",
            "Epoch 42/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 81927.3125 - mean_squared_error: 81927.3125 - val_loss: 62874.1289 - val_mean_squared_error: 62874.1289\n",
            "Epoch 43/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 81878.5000 - mean_squared_error: 81878.5000 - val_loss: 62834.0781 - val_mean_squared_error: 62834.0781\n",
            "Epoch 44/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 81829.7734 - mean_squared_error: 81829.7734 - val_loss: 62794.8594 - val_mean_squared_error: 62794.8594\n",
            "Epoch 45/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 81781.0391 - mean_squared_error: 81781.0391 - val_loss: 62753.7734 - val_mean_squared_error: 62753.7734\n",
            "Epoch 46/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 81732.4141 - mean_squared_error: 81732.4141 - val_loss: 62714.3164 - val_mean_squared_error: 62714.3164\n",
            "Epoch 47/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 81684.0078 - mean_squared_error: 81684.0078 - val_loss: 62675.4062 - val_mean_squared_error: 62675.4062\n",
            "Epoch 48/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 81635.5078 - mean_squared_error: 81635.5078 - val_loss: 62636.1055 - val_mean_squared_error: 62636.1055\n",
            "Epoch 49/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 81587.0078 - mean_squared_error: 81587.0078 - val_loss: 62596.2305 - val_mean_squared_error: 62596.2305\n",
            "Epoch 50/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 81538.5625 - mean_squared_error: 81538.5625 - val_loss: 62557.4297 - val_mean_squared_error: 62557.4297\n",
            "Epoch 51/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 81490.4062 - mean_squared_error: 81490.4062 - val_loss: 62518.4414 - val_mean_squared_error: 62518.4414\n",
            "Epoch 52/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 81442.1641 - mean_squared_error: 81442.1641 - val_loss: 62478.7695 - val_mean_squared_error: 62478.7695\n",
            "Epoch 53/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 81393.8828 - mean_squared_error: 81393.8828 - val_loss: 62439.1719 - val_mean_squared_error: 62439.1719\n",
            "Epoch 54/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 81345.7578 - mean_squared_error: 81345.7578 - val_loss: 62400.2695 - val_mean_squared_error: 62400.2695\n",
            "Epoch 55/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 81297.6953 - mean_squared_error: 81297.6953 - val_loss: 62361.1289 - val_mean_squared_error: 62361.1289\n",
            "Epoch 56/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 81249.6641 - mean_squared_error: 81249.6641 - val_loss: 62322.4062 - val_mean_squared_error: 62322.4062\n",
            "Epoch 57/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 81201.7500 - mean_squared_error: 81201.7500 - val_loss: 62282.7266 - val_mean_squared_error: 62282.7266\n",
            "Epoch 58/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 81153.8125 - mean_squared_error: 81153.8125 - val_loss: 62244.5078 - val_mean_squared_error: 62244.5078\n",
            "Epoch 59/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 81105.7969 - mean_squared_error: 81105.7969 - val_loss: 62205.5625 - val_mean_squared_error: 62205.5625\n",
            "Epoch 60/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 81058.0312 - mean_squared_error: 81058.0312 - val_loss: 62167.4492 - val_mean_squared_error: 62167.4492\n",
            "Epoch 61/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 81010.1953 - mean_squared_error: 81010.1953 - val_loss: 62126.4648 - val_mean_squared_error: 62126.4648\n",
            "Epoch 62/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 80962.5547 - mean_squared_error: 80962.5547 - val_loss: 62088.7188 - val_mean_squared_error: 62088.7188\n",
            "Epoch 63/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 80914.7266 - mean_squared_error: 80914.7266 - val_loss: 62050.1016 - val_mean_squared_error: 62050.1016\n",
            "Epoch 64/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 80867.0703 - mean_squared_error: 80867.0703 - val_loss: 62014.4297 - val_mean_squared_error: 62014.4297\n",
            "Epoch 65/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 80819.4531 - mean_squared_error: 80819.4531 - val_loss: 61972.4844 - val_mean_squared_error: 61972.4844\n",
            "Epoch 66/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 80771.7891 - mean_squared_error: 80771.7891 - val_loss: 61934.4961 - val_mean_squared_error: 61934.4961\n",
            "Epoch 67/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 80724.5156 - mean_squared_error: 80724.5156 - val_loss: 61896.9648 - val_mean_squared_error: 61896.9648\n",
            "Epoch 68/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 80677.0938 - mean_squared_error: 80677.0938 - val_loss: 61857.2031 - val_mean_squared_error: 61857.2031\n",
            "Epoch 69/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 80629.7109 - mean_squared_error: 80629.7109 - val_loss: 61818.7617 - val_mean_squared_error: 61818.7617\n",
            "Epoch 70/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 80582.4531 - mean_squared_error: 80582.4531 - val_loss: 61779.6367 - val_mean_squared_error: 61779.6367\n",
            "Epoch 71/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 80535.0312 - mean_squared_error: 80535.0312 - val_loss: 61741.9062 - val_mean_squared_error: 61741.9062\n",
            "Epoch 72/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 80487.8125 - mean_squared_error: 80487.8125 - val_loss: 61703.2773 - val_mean_squared_error: 61703.2773\n",
            "Epoch 73/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 80440.8594 - mean_squared_error: 80440.8594 - val_loss: 61667.9062 - val_mean_squared_error: 61667.9062\n",
            "Epoch 74/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 80393.7109 - mean_squared_error: 80393.7109 - val_loss: 61628.1797 - val_mean_squared_error: 61628.1797\n",
            "Epoch 75/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 80346.7891 - mean_squared_error: 80346.7891 - val_loss: 61590.0000 - val_mean_squared_error: 61590.0000\n",
            "Epoch 76/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 80299.8047 - mean_squared_error: 80299.8047 - val_loss: 61551.1016 - val_mean_squared_error: 61551.1016\n",
            "Epoch 77/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 80252.6641 - mean_squared_error: 80252.6641 - val_loss: 61516.8164 - val_mean_squared_error: 61516.8164\n",
            "Epoch 78/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 80205.7891 - mean_squared_error: 80205.7891 - val_loss: 61476.9961 - val_mean_squared_error: 61476.9961\n",
            "Epoch 79/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 80158.3984 - mean_squared_error: 80158.3984 - val_loss: 61447.4805 - val_mean_squared_error: 61447.4805\n",
            "Epoch 80/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 80111.2109 - mean_squared_error: 80111.2109 - val_loss: 61412.4727 - val_mean_squared_error: 61412.4727\n",
            "Epoch 81/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 80063.7578 - mean_squared_error: 80063.7578 - val_loss: 61377.4258 - val_mean_squared_error: 61377.4258\n",
            "Epoch 82/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 80016.8359 - mean_squared_error: 80016.8359 - val_loss: 61344.6641 - val_mean_squared_error: 61344.6641\n",
            "Epoch 83/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79969.7734 - mean_squared_error: 79969.7734 - val_loss: 61332.5039 - val_mean_squared_error: 61332.5039\n",
            "Epoch 84/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79922.5234 - mean_squared_error: 79922.5234 - val_loss: 61282.0430 - val_mean_squared_error: 61282.0430\n",
            "Epoch 85/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 79875.4531 - mean_squared_error: 79875.4531 - val_loss: 61235.5703 - val_mean_squared_error: 61235.5703\n",
            "Epoch 86/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79828.7031 - mean_squared_error: 79828.7031 - val_loss: 61221.4961 - val_mean_squared_error: 61221.4961\n",
            "Epoch 87/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79782.1094 - mean_squared_error: 79782.1094 - val_loss: 61160.7148 - val_mean_squared_error: 61160.7148\n",
            "Epoch 88/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79735.3047 - mean_squared_error: 79735.3047 - val_loss: 61153.3438 - val_mean_squared_error: 61153.3438\n",
            "Epoch 89/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 79688.7891 - mean_squared_error: 79688.7891 - val_loss: 61128.7227 - val_mean_squared_error: 61128.7227\n",
            "Epoch 90/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79642.3203 - mean_squared_error: 79642.3203 - val_loss: 61106.7148 - val_mean_squared_error: 61106.7148\n",
            "Epoch 91/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79595.8828 - mean_squared_error: 79595.8828 - val_loss: 61123.9102 - val_mean_squared_error: 61123.9102\n",
            "Epoch 92/200\n",
            "1655/1655 [==============================] - 12s 8ms/step - loss: 79550.0781 - mean_squared_error: 79550.0781 - val_loss: 61033.2070 - val_mean_squared_error: 61033.2070\n",
            "Epoch 93/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79503.8984 - mean_squared_error: 79503.8984 - val_loss: 60992.6836 - val_mean_squared_error: 60992.6836\n",
            "Epoch 94/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79457.3281 - mean_squared_error: 79457.3281 - val_loss: 60955.6133 - val_mean_squared_error: 60955.6133\n",
            "Epoch 95/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 79411.2969 - mean_squared_error: 79411.2969 - val_loss: 60933.2617 - val_mean_squared_error: 60933.2617\n",
            "Epoch 96/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79365.1484 - mean_squared_error: 79365.1484 - val_loss: 60909.1875 - val_mean_squared_error: 60909.1875\n",
            "Epoch 97/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79318.9219 - mean_squared_error: 79318.9219 - val_loss: 60868.8711 - val_mean_squared_error: 60868.8711\n",
            "Epoch 98/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79272.8594 - mean_squared_error: 79272.8594 - val_loss: 60848.5039 - val_mean_squared_error: 60848.5039\n",
            "Epoch 99/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79227.3594 - mean_squared_error: 79227.3594 - val_loss: 60810.9922 - val_mean_squared_error: 60810.9922\n",
            "Epoch 100/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79181.0703 - mean_squared_error: 79181.0703 - val_loss: 60758.8906 - val_mean_squared_error: 60758.8906\n",
            "Epoch 101/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79135.3594 - mean_squared_error: 79135.3594 - val_loss: 60729.1719 - val_mean_squared_error: 60729.1719\n",
            "Epoch 102/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79089.5781 - mean_squared_error: 79089.5781 - val_loss: 60717.9414 - val_mean_squared_error: 60717.9414\n",
            "Epoch 103/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 79043.7812 - mean_squared_error: 79043.7812 - val_loss: 60685.1680 - val_mean_squared_error: 60685.1680\n",
            "Epoch 104/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78997.9375 - mean_squared_error: 78997.9375 - val_loss: 60665.1523 - val_mean_squared_error: 60665.1523\n",
            "Epoch 105/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78952.5781 - mean_squared_error: 78952.5781 - val_loss: 60646.4805 - val_mean_squared_error: 60646.4805\n",
            "Epoch 106/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78906.6406 - mean_squared_error: 78906.6406 - val_loss: 60605.5664 - val_mean_squared_error: 60605.5664\n",
            "Epoch 107/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78861.0156 - mean_squared_error: 78861.0156 - val_loss: 60565.4688 - val_mean_squared_error: 60565.4688\n",
            "Epoch 108/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78815.6953 - mean_squared_error: 78815.6953 - val_loss: 60559.1016 - val_mean_squared_error: 60559.1016\n",
            "Epoch 109/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78770.2422 - mean_squared_error: 78770.2422 - val_loss: 60482.7461 - val_mean_squared_error: 60482.7461\n",
            "Epoch 110/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78724.7812 - mean_squared_error: 78724.7812 - val_loss: 60423.6523 - val_mean_squared_error: 60423.6523\n",
            "Epoch 111/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78679.6328 - mean_squared_error: 78679.6328 - val_loss: 60407.8281 - val_mean_squared_error: 60407.8281\n",
            "Epoch 112/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78634.1875 - mean_squared_error: 78634.1875 - val_loss: 60382.3398 - val_mean_squared_error: 60382.3398\n",
            "Epoch 113/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78589.1484 - mean_squared_error: 78589.1484 - val_loss: 60342.3516 - val_mean_squared_error: 60342.3516\n",
            "Epoch 114/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78544.5625 - mean_squared_error: 78544.5625 - val_loss: 60303.0938 - val_mean_squared_error: 60303.0938\n",
            "Epoch 115/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78499.1797 - mean_squared_error: 78499.1797 - val_loss: 60285.9805 - val_mean_squared_error: 60285.9805\n",
            "Epoch 116/200\n",
            "1655/1655 [==============================] - 12s 8ms/step - loss: 78454.0625 - mean_squared_error: 78454.0625 - val_loss: 60231.7891 - val_mean_squared_error: 60231.7891\n",
            "Epoch 117/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78409.3359 - mean_squared_error: 78409.3359 - val_loss: 60221.6133 - val_mean_squared_error: 60221.6133\n",
            "Epoch 118/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78364.1094 - mean_squared_error: 78364.1094 - val_loss: 60156.9414 - val_mean_squared_error: 60156.9414\n",
            "Epoch 119/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78319.5703 - mean_squared_error: 78319.5703 - val_loss: 60175.8945 - val_mean_squared_error: 60175.8945\n",
            "Epoch 120/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78274.6016 - mean_squared_error: 78274.6016 - val_loss: 60115.7422 - val_mean_squared_error: 60115.7422\n",
            "Epoch 121/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78229.5625 - mean_squared_error: 78229.5625 - val_loss: 60103.3203 - val_mean_squared_error: 60103.3203\n",
            "Epoch 122/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78185.1484 - mean_squared_error: 78185.1484 - val_loss: 60060.3203 - val_mean_squared_error: 60060.3203\n",
            "Epoch 123/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78140.3047 - mean_squared_error: 78140.3047 - val_loss: 59995.9492 - val_mean_squared_error: 59995.9492\n",
            "Epoch 124/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78095.7812 - mean_squared_error: 78095.7812 - val_loss: 59981.3008 - val_mean_squared_error: 59981.3008\n",
            "Epoch 125/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78051.3203 - mean_squared_error: 78051.3203 - val_loss: 59974.3789 - val_mean_squared_error: 59974.3789\n",
            "Epoch 126/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 78006.8281 - mean_squared_error: 78006.8281 - val_loss: 59934.6445 - val_mean_squared_error: 59934.6445\n",
            "Epoch 127/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77962.5078 - mean_squared_error: 77962.5078 - val_loss: 59873.7266 - val_mean_squared_error: 59873.7266\n",
            "Epoch 128/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77917.6250 - mean_squared_error: 77917.6250 - val_loss: 59856.6641 - val_mean_squared_error: 59856.6641\n",
            "Epoch 129/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77873.5078 - mean_squared_error: 77873.5078 - val_loss: 59843.7305 - val_mean_squared_error: 59843.7305\n",
            "Epoch 130/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77829.3750 - mean_squared_error: 77829.3750 - val_loss: 59796.1445 - val_mean_squared_error: 59796.1445\n",
            "Epoch 131/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77784.8125 - mean_squared_error: 77784.8125 - val_loss: 59726.5781 - val_mean_squared_error: 59726.5781\n",
            "Epoch 132/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77740.6641 - mean_squared_error: 77740.6641 - val_loss: 59751.3203 - val_mean_squared_error: 59751.3203\n",
            "Epoch 133/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77696.8984 - mean_squared_error: 77696.8984 - val_loss: 59694.9062 - val_mean_squared_error: 59694.9062\n",
            "Epoch 134/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77652.5938 - mean_squared_error: 77652.5938 - val_loss: 59750.3047 - val_mean_squared_error: 59750.3047\n",
            "Epoch 135/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77608.5781 - mean_squared_error: 77608.5781 - val_loss: 59645.9453 - val_mean_squared_error: 59645.9453\n",
            "Epoch 136/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77564.1172 - mean_squared_error: 77564.1172 - val_loss: 59637.9766 - val_mean_squared_error: 59637.9766\n",
            "Epoch 137/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77520.2656 - mean_squared_error: 77520.2656 - val_loss: 59645.8320 - val_mean_squared_error: 59645.8320\n",
            "Epoch 138/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77476.6328 - mean_squared_error: 77476.6328 - val_loss: 59571.2070 - val_mean_squared_error: 59571.2070\n",
            "Epoch 139/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77432.5625 - mean_squared_error: 77432.5625 - val_loss: 59517.8086 - val_mean_squared_error: 59517.8086\n",
            "Epoch 140/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77389.1328 - mean_squared_error: 77389.1328 - val_loss: 59492.1680 - val_mean_squared_error: 59492.1680\n",
            "Epoch 141/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77344.9375 - mean_squared_error: 77344.9375 - val_loss: 59522.7266 - val_mean_squared_error: 59522.7266\n",
            "Epoch 142/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77301.6250 - mean_squared_error: 77301.6250 - val_loss: 59449.4180 - val_mean_squared_error: 59449.4180\n",
            "Epoch 143/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77257.7969 - mean_squared_error: 77257.7969 - val_loss: 59414.0859 - val_mean_squared_error: 59414.0859\n",
            "Epoch 144/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77214.0234 - mean_squared_error: 77214.0234 - val_loss: 59410.7109 - val_mean_squared_error: 59410.7109\n",
            "Epoch 145/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77170.4453 - mean_squared_error: 77170.4453 - val_loss: 59368.8242 - val_mean_squared_error: 59368.8242\n",
            "Epoch 146/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77126.7656 - mean_squared_error: 77126.7656 - val_loss: 59362.3086 - val_mean_squared_error: 59362.3086\n",
            "Epoch 147/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77084.0938 - mean_squared_error: 77084.0938 - val_loss: 59309.5352 - val_mean_squared_error: 59309.5352\n",
            "Epoch 148/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 77040.2500 - mean_squared_error: 77040.2500 - val_loss: 59221.5781 - val_mean_squared_error: 59221.5781\n",
            "Epoch 149/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 76996.8438 - mean_squared_error: 76996.8438 - val_loss: 59281.9219 - val_mean_squared_error: 59281.9219\n",
            "Epoch 150/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 76953.2031 - mean_squared_error: 76953.2031 - val_loss: 59232.5938 - val_mean_squared_error: 59232.5938\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 59217.4570 - mean_squared_error: 59217.4570\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 1107)              3337605   \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 406)               449848    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 149)               60643     \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 54)                8100      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 20)                1100      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 7)                 147       \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 2)                 16        \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,857,462\n",
            "Trainable params: 3,857,462\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1655/1655 [==============================] - 16s 9ms/step - loss: 51570.6289 - mean_squared_error: 51570.6289 - val_loss: 41012.8438 - val_mean_squared_error: 41012.8438\n",
            "Epoch 2/200\n",
            "1655/1655 [==============================] - 15s 9ms/step - loss: 39331.2305 - mean_squared_error: 39331.2305 - val_loss: 46883.3945 - val_mean_squared_error: 46883.3945\n",
            "Epoch 3/200\n",
            "1655/1655 [==============================] - 14s 9ms/step - loss: 32635.7031 - mean_squared_error: 32635.7031 - val_loss: 53174.5234 - val_mean_squared_error: 53174.5234\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 62443.0195 - mean_squared_error: 62443.0195\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_26 (Dense)            (None, 1237)              3729555   \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 508)               628904    \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 208)               105872    \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 85)                17765     \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 35)                3010      \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 14)                504       \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 5)                 75        \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 2)                 12        \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,485,700\n",
            "Trainable params: 4,485,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1655/1655 [==============================] - 16s 9ms/step - loss: 53456.6367 - mean_squared_error: 53456.6367 - val_loss: 41234.3789 - val_mean_squared_error: 41234.3789\n",
            "Epoch 2/200\n",
            "1655/1655 [==============================] - 15s 9ms/step - loss: 41619.3438 - mean_squared_error: 41619.3438 - val_loss: 42118.1875 - val_mean_squared_error: 42118.1875\n",
            "Epoch 3/200\n",
            "1655/1655 [==============================] - 15s 9ms/step - loss: 36088.3398 - mean_squared_error: 36088.3398 - val_loss: 45221.9922 - val_mean_squared_error: 45221.9922\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 52202.6875 - mean_squared_error: 52202.6875\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_35 (Dense)            (None, 1352)              4076280   \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 607)               821271    \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 272)               165376    \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 122)               33306     \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 54)                6642      \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 24)                1320      \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 11)                275       \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 4)                 48        \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 2)                 10        \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,104,531\n",
            "Trainable params: 5,104,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1655/1655 [==============================] - 17s 10ms/step - loss: 49896.4219 - mean_squared_error: 49896.4219 - val_loss: 41284.5117 - val_mean_squared_error: 41284.5117\n",
            "Epoch 2/200\n",
            "1655/1655 [==============================] - 17s 10ms/step - loss: 36221.1875 - mean_squared_error: 36221.1875 - val_loss: 51559.2656 - val_mean_squared_error: 51559.2656\n",
            "Epoch 3/200\n",
            "1655/1655 [==============================] - 17s 10ms/step - loss: 28609.4980 - mean_squared_error: 28609.4980 - val_loss: 70519.1953 - val_mean_squared_error: 70519.1953\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 91615.1406 - mean_squared_error: 91615.1406\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_45 (Dense)            (None, 1454)              4383810   \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 702)               1021410   \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 339)               238317    \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 163)               55420     \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 79)                12956     \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 38)                3040      \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 18)                702       \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 8)                 152       \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 2)                 10        \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,715,856\n",
            "Trainable params: 5,715,856\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1655/1655 [==============================] - 19s 11ms/step - loss: 53475.4023 - mean_squared_error: 53475.4023 - val_loss: 41545.6328 - val_mean_squared_error: 41545.6328\n",
            "Epoch 2/200\n",
            "1655/1655 [==============================] - 18s 11ms/step - loss: 41238.5625 - mean_squared_error: 41238.5625 - val_loss: 44182.5078 - val_mean_squared_error: 44182.5078\n",
            "Epoch 3/200\n",
            "1655/1655 [==============================] - 18s 11ms/step - loss: 35416.9961 - mean_squared_error: 35416.9961 - val_loss: 46459.7891 - val_mean_squared_error: 46459.7891\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 54188.2500 - mean_squared_error: 54188.2500\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_56 (Dense)            (None, 1546)              4661190   \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 793)               1226771   \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 406)               322364    \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 208)               84656     \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 107)               22363     \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 54)                5832      \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 28)                1540      \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 14)                406       \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 7)                 105       \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 3)                 24        \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 1)                 4         \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,325,257\n",
            "Trainable params: 6,325,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1655/1655 [==============================] - 21s 12ms/step - loss: 83972.3750 - mean_squared_error: 83972.3750 - val_loss: 64549.4414 - val_mean_squared_error: 64549.4414\n",
            "Epoch 2/200\n",
            "1655/1655 [==============================] - 19s 11ms/step - loss: 83921.3359 - mean_squared_error: 83921.3359 - val_loss: 64507.4414 - val_mean_squared_error: 64507.4414\n",
            "Epoch 3/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 83870.2969 - mean_squared_error: 83870.2969 - val_loss: 64465.4258 - val_mean_squared_error: 64465.4258\n",
            "Epoch 4/200\n",
            "1655/1655 [==============================] - 19s 11ms/step - loss: 83819.6406 - mean_squared_error: 83819.6406 - val_loss: 64423.6875 - val_mean_squared_error: 64423.6875\n",
            "Epoch 5/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 83768.9531 - mean_squared_error: 83768.9531 - val_loss: 64381.9180 - val_mean_squared_error: 64381.9180\n",
            "Epoch 6/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 83718.0703 - mean_squared_error: 83718.0703 - val_loss: 64340.1094 - val_mean_squared_error: 64340.1094\n",
            "Epoch 7/200\n",
            "1655/1655 [==============================] - 19s 11ms/step - loss: 83667.2969 - mean_squared_error: 83667.2969 - val_loss: 64298.3477 - val_mean_squared_error: 64298.3477\n",
            "Epoch 8/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 83616.6875 - mean_squared_error: 83616.6875 - val_loss: 64256.7969 - val_mean_squared_error: 64256.7969\n",
            "Epoch 9/200\n",
            "1655/1655 [==============================] - 19s 11ms/step - loss: 83566.1484 - mean_squared_error: 83566.1484 - val_loss: 64215.1094 - val_mean_squared_error: 64215.1094\n",
            "Epoch 10/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 83515.5703 - mean_squared_error: 83515.5703 - val_loss: 64173.5977 - val_mean_squared_error: 64173.5977\n",
            "Epoch 11/200\n",
            "1655/1655 [==============================] - 19s 11ms/step - loss: 83465.1797 - mean_squared_error: 83465.1797 - val_loss: 64132.0820 - val_mean_squared_error: 64132.0820\n",
            "Epoch 12/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 83414.5859 - mean_squared_error: 83414.5859 - val_loss: 64090.5977 - val_mean_squared_error: 64090.5977\n",
            "Epoch 13/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 83364.1797 - mean_squared_error: 83364.1797 - val_loss: 64049.2969 - val_mean_squared_error: 64049.2969\n",
            "Epoch 14/200\n",
            "1655/1655 [==============================] - 19s 11ms/step - loss: 83313.9375 - mean_squared_error: 83313.9375 - val_loss: 64007.9648 - val_mean_squared_error: 64007.9648\n",
            "Epoch 15/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 83263.7969 - mean_squared_error: 83263.7969 - val_loss: 63966.6211 - val_mean_squared_error: 63966.6211\n",
            "Epoch 16/200\n",
            "1655/1655 [==============================] - 19s 11ms/step - loss: 83213.5312 - mean_squared_error: 83213.5312 - val_loss: 63925.4180 - val_mean_squared_error: 63925.4180\n",
            "Epoch 17/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 83163.3125 - mean_squared_error: 83163.3125 - val_loss: 63884.3008 - val_mean_squared_error: 63884.3008\n",
            "Epoch 18/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 83113.2031 - mean_squared_error: 83113.2031 - val_loss: 63843.1719 - val_mean_squared_error: 63843.1719\n",
            "Epoch 19/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 83063.1328 - mean_squared_error: 83063.1328 - val_loss: 63802.1250 - val_mean_squared_error: 63802.1250\n",
            "Epoch 20/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 83013.0469 - mean_squared_error: 83013.0469 - val_loss: 63761.0039 - val_mean_squared_error: 63761.0039\n",
            "Epoch 21/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 82963.1562 - mean_squared_error: 82963.1562 - val_loss: 63720.2383 - val_mean_squared_error: 63720.2383\n",
            "Epoch 22/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 82913.4922 - mean_squared_error: 82913.4922 - val_loss: 63679.3008 - val_mean_squared_error: 63679.3008\n",
            "Epoch 23/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 82863.6094 - mean_squared_error: 82863.6094 - val_loss: 63638.5430 - val_mean_squared_error: 63638.5430\n",
            "Epoch 24/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 82813.8828 - mean_squared_error: 82813.8828 - val_loss: 63597.7695 - val_mean_squared_error: 63597.7695\n",
            "Epoch 25/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 82764.1016 - mean_squared_error: 82764.1016 - val_loss: 63556.9688 - val_mean_squared_error: 63556.9688\n",
            "Epoch 26/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 82714.6406 - mean_squared_error: 82714.6406 - val_loss: 63516.4414 - val_mean_squared_error: 63516.4414\n",
            "Epoch 27/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 82664.9219 - mean_squared_error: 82664.9219 - val_loss: 63475.6914 - val_mean_squared_error: 63475.6914\n",
            "Epoch 28/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 82615.4141 - mean_squared_error: 82615.4141 - val_loss: 63435.1328 - val_mean_squared_error: 63435.1328\n",
            "Epoch 29/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 82565.8359 - mean_squared_error: 82565.8359 - val_loss: 63394.6133 - val_mean_squared_error: 63394.6133\n",
            "Epoch 30/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 82516.3359 - mean_squared_error: 82516.3359 - val_loss: 63354.1680 - val_mean_squared_error: 63354.1680\n",
            "Epoch 31/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 82466.8750 - mean_squared_error: 82466.8750 - val_loss: 63313.6875 - val_mean_squared_error: 63313.6875\n",
            "Epoch 32/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 82417.6953 - mean_squared_error: 82417.6953 - val_loss: 63273.4648 - val_mean_squared_error: 63273.4648\n",
            "Epoch 33/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 82368.4375 - mean_squared_error: 82368.4375 - val_loss: 63233.0117 - val_mean_squared_error: 63233.0117\n",
            "Epoch 34/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 82319.1094 - mean_squared_error: 82319.1094 - val_loss: 63192.8125 - val_mean_squared_error: 63192.8125\n",
            "Epoch 35/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 82269.9531 - mean_squared_error: 82269.9531 - val_loss: 63152.5078 - val_mean_squared_error: 63152.5078\n",
            "Epoch 36/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 82220.7969 - mean_squared_error: 82220.7969 - val_loss: 63112.3828 - val_mean_squared_error: 63112.3828\n",
            "Epoch 37/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 82171.6328 - mean_squared_error: 82171.6328 - val_loss: 63072.2930 - val_mean_squared_error: 63072.2930\n",
            "Epoch 38/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 82122.7031 - mean_squared_error: 82122.7031 - val_loss: 63032.3672 - val_mean_squared_error: 63032.3672\n",
            "Epoch 39/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 82073.7812 - mean_squared_error: 82073.7812 - val_loss: 62992.3633 - val_mean_squared_error: 62992.3633\n",
            "Epoch 40/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 82025.0859 - mean_squared_error: 82025.0859 - val_loss: 62952.5586 - val_mean_squared_error: 62952.5586\n",
            "Epoch 41/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 81976.1406 - mean_squared_error: 81976.1406 - val_loss: 62912.6484 - val_mean_squared_error: 62912.6484\n",
            "Epoch 42/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 81927.3438 - mean_squared_error: 81927.3438 - val_loss: 62872.8125 - val_mean_squared_error: 62872.8125\n",
            "Epoch 43/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 81878.6406 - mean_squared_error: 81878.6406 - val_loss: 62833.1250 - val_mean_squared_error: 62833.1250\n",
            "Epoch 44/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 81830.0391 - mean_squared_error: 81830.0391 - val_loss: 62793.3867 - val_mean_squared_error: 62793.3867\n",
            "Epoch 45/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 81781.4375 - mean_squared_error: 81781.4375 - val_loss: 62753.7227 - val_mean_squared_error: 62753.7227\n",
            "Epoch 46/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 81732.7031 - mean_squared_error: 81732.7031 - val_loss: 62714.0352 - val_mean_squared_error: 62714.0352\n",
            "Epoch 47/200\n",
            "1655/1655 [==============================] - 19s 11ms/step - loss: 81684.2422 - mean_squared_error: 81684.2422 - val_loss: 62674.6016 - val_mean_squared_error: 62674.6016\n",
            "Epoch 48/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 81635.7969 - mean_squared_error: 81635.7969 - val_loss: 62635.1680 - val_mean_squared_error: 62635.1680\n",
            "Epoch 49/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 81587.4922 - mean_squared_error: 81587.4922 - val_loss: 62595.6289 - val_mean_squared_error: 62595.6289\n",
            "Epoch 50/200\n",
            "1655/1655 [==============================] - 19s 11ms/step - loss: 81538.9141 - mean_squared_error: 81538.9141 - val_loss: 62556.1445 - val_mean_squared_error: 62556.1445\n",
            "Epoch 51/200\n",
            "1655/1655 [==============================] - 19s 11ms/step - loss: 81490.7500 - mean_squared_error: 81490.7500 - val_loss: 62517.0078 - val_mean_squared_error: 62517.0078\n",
            "Epoch 52/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 81442.7500 - mean_squared_error: 81442.7500 - val_loss: 62477.8945 - val_mean_squared_error: 62477.8945\n",
            "Epoch 53/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 81394.5938 - mean_squared_error: 81394.5938 - val_loss: 62438.5781 - val_mean_squared_error: 62438.5781\n",
            "Epoch 54/200\n",
            "1655/1655 [==============================] - 19s 11ms/step - loss: 81346.2812 - mean_squared_error: 81346.2812 - val_loss: 62399.3750 - val_mean_squared_error: 62399.3750\n",
            "Epoch 55/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 81298.2969 - mean_squared_error: 81298.2969 - val_loss: 62360.3203 - val_mean_squared_error: 62360.3203\n",
            "Epoch 56/200\n",
            "1655/1655 [==============================] - 19s 11ms/step - loss: 81250.3438 - mean_squared_error: 81250.3438 - val_loss: 62321.2617 - val_mean_squared_error: 62321.2617\n",
            "Epoch 57/200\n",
            "1655/1655 [==============================] - 19s 11ms/step - loss: 81202.3594 - mean_squared_error: 81202.3594 - val_loss: 62282.2695 - val_mean_squared_error: 62282.2695\n",
            "Epoch 58/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 81154.4531 - mean_squared_error: 81154.4531 - val_loss: 62243.3320 - val_mean_squared_error: 62243.3320\n",
            "Epoch 59/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 81106.4766 - mean_squared_error: 81106.4766 - val_loss: 62204.2617 - val_mean_squared_error: 62204.2617\n",
            "Epoch 60/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 81058.6016 - mean_squared_error: 81058.6016 - val_loss: 62165.5078 - val_mean_squared_error: 62165.5078\n",
            "Epoch 61/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 81010.8438 - mean_squared_error: 81010.8438 - val_loss: 62126.6016 - val_mean_squared_error: 62126.6016\n",
            "Epoch 62/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80963.2188 - mean_squared_error: 80963.2188 - val_loss: 62087.9375 - val_mean_squared_error: 62087.9375\n",
            "Epoch 63/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 80915.5938 - mean_squared_error: 80915.5938 - val_loss: 62049.2500 - val_mean_squared_error: 62049.2500\n",
            "Epoch 64/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 80868.0000 - mean_squared_error: 80868.0000 - val_loss: 62010.7109 - val_mean_squared_error: 62010.7109\n",
            "Epoch 65/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80820.5078 - mean_squared_error: 80820.5078 - val_loss: 61972.1055 - val_mean_squared_error: 61972.1055\n",
            "Epoch 66/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80773.0000 - mean_squared_error: 80773.0000 - val_loss: 61933.5000 - val_mean_squared_error: 61933.5000\n",
            "Epoch 67/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80725.5469 - mean_squared_error: 80725.5469 - val_loss: 61895.0586 - val_mean_squared_error: 61895.0586\n",
            "Epoch 68/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80678.2500 - mean_squared_error: 80678.2500 - val_loss: 61856.6445 - val_mean_squared_error: 61856.6445\n",
            "Epoch 69/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80630.6953 - mean_squared_error: 80630.6953 - val_loss: 61818.1250 - val_mean_squared_error: 61818.1250\n",
            "Epoch 70/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80583.5000 - mean_squared_error: 80583.5000 - val_loss: 61779.8750 - val_mean_squared_error: 61779.8750\n",
            "Epoch 71/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 80536.3516 - mean_squared_error: 80536.3516 - val_loss: 61741.6953 - val_mean_squared_error: 61741.6953\n",
            "Epoch 72/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80489.2891 - mean_squared_error: 80489.2891 - val_loss: 61703.4688 - val_mean_squared_error: 61703.4688\n",
            "Epoch 73/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80442.0234 - mean_squared_error: 80442.0234 - val_loss: 61665.2695 - val_mean_squared_error: 61665.2695\n",
            "Epoch 74/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80394.9297 - mean_squared_error: 80394.9297 - val_loss: 61627.1094 - val_mean_squared_error: 61627.1094\n",
            "Epoch 75/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80348.0391 - mean_squared_error: 80348.0391 - val_loss: 61589.1875 - val_mean_squared_error: 61589.1875\n",
            "Epoch 76/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 80301.0859 - mean_squared_error: 80301.0859 - val_loss: 61551.1758 - val_mean_squared_error: 61551.1758\n",
            "Epoch 77/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 80254.1719 - mean_squared_error: 80254.1719 - val_loss: 61513.1797 - val_mean_squared_error: 61513.1797\n",
            "Epoch 78/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 80207.2578 - mean_squared_error: 80207.2578 - val_loss: 61475.1875 - val_mean_squared_error: 61475.1875\n",
            "Epoch 79/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80160.4297 - mean_squared_error: 80160.4297 - val_loss: 61437.4336 - val_mean_squared_error: 61437.4336\n",
            "Epoch 80/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80113.8281 - mean_squared_error: 80113.8281 - val_loss: 61399.6641 - val_mean_squared_error: 61399.6641\n",
            "Epoch 81/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80067.0703 - mean_squared_error: 80067.0703 - val_loss: 61361.9453 - val_mean_squared_error: 61361.9453\n",
            "Epoch 82/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 80020.4453 - mean_squared_error: 80020.4453 - val_loss: 61324.1562 - val_mean_squared_error: 61324.1562\n",
            "Epoch 83/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 79973.7969 - mean_squared_error: 79973.7969 - val_loss: 61286.5117 - val_mean_squared_error: 61286.5117\n",
            "Epoch 84/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 79927.2188 - mean_squared_error: 79927.2188 - val_loss: 61248.8984 - val_mean_squared_error: 61248.8984\n",
            "Epoch 85/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 79880.8359 - mean_squared_error: 79880.8359 - val_loss: 61211.5156 - val_mean_squared_error: 61211.5156\n",
            "Epoch 86/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 79834.6406 - mean_squared_error: 79834.6406 - val_loss: 61174.1953 - val_mean_squared_error: 61174.1953\n",
            "Epoch 87/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 79788.3281 - mean_squared_error: 79788.3281 - val_loss: 61136.7188 - val_mean_squared_error: 61136.7188\n",
            "Epoch 88/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 79741.9375 - mean_squared_error: 79741.9375 - val_loss: 61099.3984 - val_mean_squared_error: 61099.3984\n",
            "Epoch 89/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 79695.8672 - mean_squared_error: 79695.8672 - val_loss: 61062.2500 - val_mean_squared_error: 61062.2500\n",
            "Epoch 90/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 79649.7188 - mean_squared_error: 79649.7188 - val_loss: 61024.9492 - val_mean_squared_error: 61024.9492\n",
            "Epoch 91/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 79603.6797 - mean_squared_error: 79603.6797 - val_loss: 60987.8125 - val_mean_squared_error: 60987.8125\n",
            "Epoch 92/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 79557.5078 - mean_squared_error: 79557.5078 - val_loss: 60950.6562 - val_mean_squared_error: 60950.6562\n",
            "Epoch 93/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 79511.4531 - mean_squared_error: 79511.4531 - val_loss: 60913.5820 - val_mean_squared_error: 60913.5820\n",
            "Epoch 94/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 79465.5938 - mean_squared_error: 79465.5938 - val_loss: 60876.6680 - val_mean_squared_error: 60876.6680\n",
            "Epoch 95/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 79419.7812 - mean_squared_error: 79419.7812 - val_loss: 60839.6797 - val_mean_squared_error: 60839.6797\n",
            "Epoch 96/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 79374.0156 - mean_squared_error: 79374.0156 - val_loss: 60802.7969 - val_mean_squared_error: 60802.7969\n",
            "Epoch 97/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 79328.1562 - mean_squared_error: 79328.1562 - val_loss: 60765.8047 - val_mean_squared_error: 60765.8047\n",
            "Epoch 98/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 79282.2344 - mean_squared_error: 79282.2344 - val_loss: 60729.1016 - val_mean_squared_error: 60729.1016\n",
            "Epoch 99/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 79236.7109 - mean_squared_error: 79236.7109 - val_loss: 60692.2852 - val_mean_squared_error: 60692.2852\n",
            "Epoch 100/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 79191.0000 - mean_squared_error: 79191.0000 - val_loss: 60655.6406 - val_mean_squared_error: 60655.6406\n",
            "Epoch 101/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 79145.5234 - mean_squared_error: 79145.5234 - val_loss: 60618.9180 - val_mean_squared_error: 60618.9180\n",
            "Epoch 102/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 79099.7500 - mean_squared_error: 79099.7500 - val_loss: 60582.2656 - val_mean_squared_error: 60582.2656\n",
            "Epoch 103/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 79054.3281 - mean_squared_error: 79054.3281 - val_loss: 60545.6523 - val_mean_squared_error: 60545.6523\n",
            "Epoch 104/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 79008.8516 - mean_squared_error: 79008.8516 - val_loss: 60509.1875 - val_mean_squared_error: 60509.1875\n",
            "Epoch 105/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 78963.5547 - mean_squared_error: 78963.5547 - val_loss: 60472.8398 - val_mean_squared_error: 60472.8398\n",
            "Epoch 106/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 78918.3047 - mean_squared_error: 78918.3047 - val_loss: 60436.3906 - val_mean_squared_error: 60436.3906\n",
            "Epoch 107/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 78872.9609 - mean_squared_error: 78872.9609 - val_loss: 60400.0078 - val_mean_squared_error: 60400.0078\n",
            "Epoch 108/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 78827.6875 - mean_squared_error: 78827.6875 - val_loss: 60363.6953 - val_mean_squared_error: 60363.6953\n",
            "Epoch 109/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 78782.5469 - mean_squared_error: 78782.5469 - val_loss: 60327.4844 - val_mean_squared_error: 60327.4844\n",
            "Epoch 110/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 78737.5234 - mean_squared_error: 78737.5234 - val_loss: 60291.2344 - val_mean_squared_error: 60291.2344\n",
            "Epoch 111/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 78692.4922 - mean_squared_error: 78692.4922 - val_loss: 60255.2344 - val_mean_squared_error: 60255.2344\n",
            "Epoch 112/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 78647.5547 - mean_squared_error: 78647.5547 - val_loss: 60219.1250 - val_mean_squared_error: 60219.1250\n",
            "Epoch 113/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 78602.4297 - mean_squared_error: 78602.4297 - val_loss: 60183.1133 - val_mean_squared_error: 60183.1133\n",
            "Epoch 114/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 78557.5703 - mean_squared_error: 78557.5703 - val_loss: 60147.0977 - val_mean_squared_error: 60147.0977\n",
            "Epoch 115/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 78512.5938 - mean_squared_error: 78512.5938 - val_loss: 60111.1172 - val_mean_squared_error: 60111.1172\n",
            "Epoch 116/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 78467.8203 - mean_squared_error: 78467.8203 - val_loss: 60075.2539 - val_mean_squared_error: 60075.2539\n",
            "Epoch 117/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 78423.2031 - mean_squared_error: 78423.2031 - val_loss: 60039.5156 - val_mean_squared_error: 60039.5156\n",
            "Epoch 118/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 78378.4844 - mean_squared_error: 78378.4844 - val_loss: 60003.6797 - val_mean_squared_error: 60003.6797\n",
            "Epoch 119/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 78333.7656 - mean_squared_error: 78333.7656 - val_loss: 59967.9258 - val_mean_squared_error: 59967.9258\n",
            "Epoch 120/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 78289.3906 - mean_squared_error: 78289.3906 - val_loss: 59932.4961 - val_mean_squared_error: 59932.4961\n",
            "Epoch 121/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 78244.7969 - mean_squared_error: 78244.7969 - val_loss: 59896.7383 - val_mean_squared_error: 59896.7383\n",
            "Epoch 122/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 78200.3828 - mean_squared_error: 78200.3828 - val_loss: 59861.3711 - val_mean_squared_error: 59861.3711\n",
            "Epoch 123/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 78156.0781 - mean_squared_error: 78156.0781 - val_loss: 59825.9062 - val_mean_squared_error: 59825.9062\n",
            "Epoch 124/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 78111.6172 - mean_squared_error: 78111.6172 - val_loss: 59790.3477 - val_mean_squared_error: 59790.3477\n",
            "Epoch 125/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 78067.3047 - mean_squared_error: 78067.3047 - val_loss: 59755.0195 - val_mean_squared_error: 59755.0195\n",
            "Epoch 126/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 78023.1641 - mean_squared_error: 78023.1641 - val_loss: 59719.7500 - val_mean_squared_error: 59719.7500\n",
            "Epoch 127/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 77979.0078 - mean_squared_error: 77979.0078 - val_loss: 59684.5664 - val_mean_squared_error: 59684.5664\n",
            "Epoch 128/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 77935.0156 - mean_squared_error: 77935.0156 - val_loss: 59649.2852 - val_mean_squared_error: 59649.2852\n",
            "Epoch 129/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 77890.8906 - mean_squared_error: 77890.8906 - val_loss: 59614.2109 - val_mean_squared_error: 59614.2109\n",
            "Epoch 130/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 77846.7344 - mean_squared_error: 77846.7344 - val_loss: 59578.9883 - val_mean_squared_error: 59578.9883\n",
            "Epoch 131/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 77803.0156 - mean_squared_error: 77803.0156 - val_loss: 59544.0938 - val_mean_squared_error: 59544.0938\n",
            "Epoch 132/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 77759.1875 - mean_squared_error: 77759.1875 - val_loss: 59509.2070 - val_mean_squared_error: 59509.2070\n",
            "Epoch 133/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 77715.4766 - mean_squared_error: 77715.4766 - val_loss: 59474.1953 - val_mean_squared_error: 59474.1953\n",
            "Epoch 134/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 77671.6250 - mean_squared_error: 77671.6250 - val_loss: 59439.3359 - val_mean_squared_error: 59439.3359\n",
            "Epoch 135/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 77627.9219 - mean_squared_error: 77627.9219 - val_loss: 59404.5352 - val_mean_squared_error: 59404.5352\n",
            "Epoch 136/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 77584.1719 - mean_squared_error: 77584.1719 - val_loss: 59369.6797 - val_mean_squared_error: 59369.6797\n",
            "Epoch 137/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 77540.5234 - mean_squared_error: 77540.5234 - val_loss: 59334.9219 - val_mean_squared_error: 59334.9219\n",
            "Epoch 138/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 77497.0078 - mean_squared_error: 77497.0078 - val_loss: 59300.3477 - val_mean_squared_error: 59300.3477\n",
            "Epoch 139/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 77453.4922 - mean_squared_error: 77453.4922 - val_loss: 59265.6016 - val_mean_squared_error: 59265.6016\n",
            "Epoch 140/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 77409.9141 - mean_squared_error: 77409.9141 - val_loss: 59231.0586 - val_mean_squared_error: 59231.0586\n",
            "Epoch 141/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 77366.4609 - mean_squared_error: 77366.4609 - val_loss: 59196.4023 - val_mean_squared_error: 59196.4023\n",
            "Epoch 142/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 77323.0781 - mean_squared_error: 77323.0781 - val_loss: 59161.9570 - val_mean_squared_error: 59161.9570\n",
            "Epoch 143/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 77279.6953 - mean_squared_error: 77279.6953 - val_loss: 59127.5352 - val_mean_squared_error: 59127.5352\n",
            "Epoch 144/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 77236.5078 - mean_squared_error: 77236.5078 - val_loss: 59093.2461 - val_mean_squared_error: 59093.2461\n",
            "Epoch 145/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 77193.2188 - mean_squared_error: 77193.2188 - val_loss: 59058.8008 - val_mean_squared_error: 59058.8008\n",
            "Epoch 146/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 77150.1953 - mean_squared_error: 77150.1953 - val_loss: 59024.6797 - val_mean_squared_error: 59024.6797\n",
            "Epoch 147/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 77107.1328 - mean_squared_error: 77107.1328 - val_loss: 58990.4453 - val_mean_squared_error: 58990.4453\n",
            "Epoch 148/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 77063.9844 - mean_squared_error: 77063.9844 - val_loss: 58956.3320 - val_mean_squared_error: 58956.3320\n",
            "Epoch 149/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 77021.1484 - mean_squared_error: 77021.1484 - val_loss: 58922.2578 - val_mean_squared_error: 58922.2578\n",
            "Epoch 150/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76978.2422 - mean_squared_error: 76978.2422 - val_loss: 58888.3125 - val_mean_squared_error: 58888.3125\n",
            "Epoch 151/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 76935.5781 - mean_squared_error: 76935.5781 - val_loss: 58854.4336 - val_mean_squared_error: 58854.4336\n",
            "Epoch 152/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 76892.7344 - mean_squared_error: 76892.7344 - val_loss: 58820.4844 - val_mean_squared_error: 58820.4844\n",
            "Epoch 153/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 76849.9766 - mean_squared_error: 76849.9766 - val_loss: 58786.6250 - val_mean_squared_error: 58786.6250\n",
            "Epoch 154/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76807.1875 - mean_squared_error: 76807.1875 - val_loss: 58752.7188 - val_mean_squared_error: 58752.7188\n",
            "Epoch 155/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76764.5078 - mean_squared_error: 76764.5078 - val_loss: 58718.9883 - val_mean_squared_error: 58718.9883\n",
            "Epoch 156/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76721.9297 - mean_squared_error: 76721.9297 - val_loss: 58685.2461 - val_mean_squared_error: 58685.2461\n",
            "Epoch 157/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76679.3203 - mean_squared_error: 76679.3203 - val_loss: 58651.5547 - val_mean_squared_error: 58651.5547\n",
            "Epoch 158/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76636.8359 - mean_squared_error: 76636.8359 - val_loss: 58617.9453 - val_mean_squared_error: 58617.9453\n",
            "Epoch 159/200\n",
            "1655/1655 [==============================] - 19s 12ms/step - loss: 76594.4062 - mean_squared_error: 76594.4062 - val_loss: 58584.3516 - val_mean_squared_error: 58584.3516\n",
            "Epoch 160/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76551.9609 - mean_squared_error: 76551.9609 - val_loss: 58550.8438 - val_mean_squared_error: 58550.8438\n",
            "Epoch 161/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76509.7891 - mean_squared_error: 76509.7891 - val_loss: 58517.4961 - val_mean_squared_error: 58517.4961\n",
            "Epoch 162/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76467.4062 - mean_squared_error: 76467.4062 - val_loss: 58484.0469 - val_mean_squared_error: 58484.0469\n",
            "Epoch 163/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76425.2969 - mean_squared_error: 76425.2969 - val_loss: 58450.8594 - val_mean_squared_error: 58450.8594\n",
            "Epoch 164/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76383.1328 - mean_squared_error: 76383.1328 - val_loss: 58417.4258 - val_mean_squared_error: 58417.4258\n",
            "Epoch 165/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76340.9453 - mean_squared_error: 76340.9453 - val_loss: 58384.2656 - val_mean_squared_error: 58384.2656\n",
            "Epoch 166/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76299.0078 - mean_squared_error: 76299.0078 - val_loss: 58351.1172 - val_mean_squared_error: 58351.1172\n",
            "Epoch 167/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76256.9297 - mean_squared_error: 76256.9297 - val_loss: 58317.8633 - val_mean_squared_error: 58317.8633\n",
            "Epoch 168/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76214.9141 - mean_squared_error: 76214.9141 - val_loss: 58284.8086 - val_mean_squared_error: 58284.8086\n",
            "Epoch 169/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76173.0859 - mean_squared_error: 76173.0859 - val_loss: 58251.8281 - val_mean_squared_error: 58251.8281\n",
            "Epoch 170/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76131.2812 - mean_squared_error: 76131.2812 - val_loss: 58218.9102 - val_mean_squared_error: 58218.9102\n",
            "Epoch 171/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 76089.4844 - mean_squared_error: 76089.4844 - val_loss: 58185.9453 - val_mean_squared_error: 58185.9453\n",
            "Epoch 172/200\n",
            "1655/1655 [==============================] - 21s 13ms/step - loss: 76047.7266 - mean_squared_error: 76047.7266 - val_loss: 58153.1094 - val_mean_squared_error: 58153.1094\n",
            "Epoch 173/200\n",
            "1655/1655 [==============================] - 21s 12ms/step - loss: 76006.0547 - mean_squared_error: 76006.0547 - val_loss: 58120.1562 - val_mean_squared_error: 58120.1562\n",
            "Epoch 174/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75964.4141 - mean_squared_error: 75964.4141 - val_loss: 58087.5430 - val_mean_squared_error: 58087.5430\n",
            "Epoch 175/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75922.9609 - mean_squared_error: 75922.9609 - val_loss: 58054.9141 - val_mean_squared_error: 58054.9141\n",
            "Epoch 176/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75881.6328 - mean_squared_error: 75881.6328 - val_loss: 58022.3906 - val_mean_squared_error: 58022.3906\n",
            "Epoch 177/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75840.2500 - mean_squared_error: 75840.2500 - val_loss: 57989.8477 - val_mean_squared_error: 57989.8477\n",
            "Epoch 178/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75798.7188 - mean_squared_error: 75798.7188 - val_loss: 57957.1797 - val_mean_squared_error: 57957.1797\n",
            "Epoch 179/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75757.3828 - mean_squared_error: 75757.3828 - val_loss: 57924.6523 - val_mean_squared_error: 57924.6523\n",
            "Epoch 180/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75716.1172 - mean_squared_error: 75716.1172 - val_loss: 57892.2773 - val_mean_squared_error: 57892.2773\n",
            "Epoch 181/200\n",
            "1655/1655 [==============================] - 21s 12ms/step - loss: 75674.8516 - mean_squared_error: 75674.8516 - val_loss: 57859.7891 - val_mean_squared_error: 57859.7891\n",
            "Epoch 182/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75633.5938 - mean_squared_error: 75633.5938 - val_loss: 57827.5156 - val_mean_squared_error: 57827.5156\n",
            "Epoch 183/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75592.5781 - mean_squared_error: 75592.5781 - val_loss: 57795.3281 - val_mean_squared_error: 57795.3281\n",
            "Epoch 184/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75551.4219 - mean_squared_error: 75551.4219 - val_loss: 57763.0000 - val_mean_squared_error: 57763.0000\n",
            "Epoch 185/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75510.3281 - mean_squared_error: 75510.3281 - val_loss: 57730.7773 - val_mean_squared_error: 57730.7773\n",
            "Epoch 186/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75469.2656 - mean_squared_error: 75469.2656 - val_loss: 57698.5977 - val_mean_squared_error: 57698.5977\n",
            "Epoch 187/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75428.3594 - mean_squared_error: 75428.3594 - val_loss: 57666.5469 - val_mean_squared_error: 57666.5469\n",
            "Epoch 188/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75387.6328 - mean_squared_error: 75387.6328 - val_loss: 57634.5898 - val_mean_squared_error: 57634.5898\n",
            "Epoch 189/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75346.6406 - mean_squared_error: 75346.6406 - val_loss: 57602.5078 - val_mean_squared_error: 57602.5078\n",
            "Epoch 190/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75305.9219 - mean_squared_error: 75305.9219 - val_loss: 57570.6719 - val_mean_squared_error: 57570.6719\n",
            "Epoch 191/200\n",
            "1655/1655 [==============================] - 21s 12ms/step - loss: 75265.2188 - mean_squared_error: 75265.2188 - val_loss: 57538.7930 - val_mean_squared_error: 57538.7930\n",
            "Epoch 192/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75224.6641 - mean_squared_error: 75224.6641 - val_loss: 57507.1289 - val_mean_squared_error: 57507.1289\n",
            "Epoch 193/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75184.0781 - mean_squared_error: 75184.0781 - val_loss: 57475.2500 - val_mean_squared_error: 57475.2500\n",
            "Epoch 194/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75143.6172 - mean_squared_error: 75143.6172 - val_loss: 57443.6680 - val_mean_squared_error: 57443.6680\n",
            "Epoch 195/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75103.0469 - mean_squared_error: 75103.0469 - val_loss: 57411.9844 - val_mean_squared_error: 57411.9844\n",
            "Epoch 196/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75062.6250 - mean_squared_error: 75062.6250 - val_loss: 57380.4375 - val_mean_squared_error: 57380.4375\n",
            "Epoch 197/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 75022.3516 - mean_squared_error: 75022.3516 - val_loss: 57348.9102 - val_mean_squared_error: 57348.9102\n",
            "Epoch 198/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 74982.0000 - mean_squared_error: 74982.0000 - val_loss: 57317.3633 - val_mean_squared_error: 57317.3633\n",
            "Epoch 199/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 74941.7344 - mean_squared_error: 74941.7344 - val_loss: 57286.0469 - val_mean_squared_error: 57286.0469\n",
            "Epoch 200/200\n",
            "1655/1655 [==============================] - 20s 12ms/step - loss: 74901.6562 - mean_squared_error: 74901.6562 - val_loss: 57254.7500 - val_mean_squared_error: 57254.7500\n",
            "144/144 [==============================] - 1s 6ms/step - loss: 57370.1328 - mean_squared_error: 57370.1328\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_68 (Dense)            (None, 1627)              4905405   \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 878)               1429384   \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 474)               416646    \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 256)               121600    \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 138)               35466     \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 74)                10286     \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 40)                3000      \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 21)                861       \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 11)                242       \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 6)                 72        \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 3)                 21        \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 1)                 4         \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,922,989\n",
            "Trainable params: 6,922,989\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gRboF3wO1ImK",
        "outputId": "d858cca2-c2d1-4dc3-a72d-29dd25e98af0"
      },
      "source": [
        "train_mse = []\n",
        "val_mse = []\n",
        "test_mse = []\n",
        "for current_model in models_4_layers_list:\n",
        "\n",
        "  current_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4)\n",
        "              ,loss=\"mean_squared_error\"\n",
        "              ,metrics=['mean_squared_error'])\n",
        "  \n",
        "  current_model.summary()\n",
        "\n",
        "  history = current_model.fit(training_x, training_y ,\n",
        "                      epochs = 200 ,validation_data=(val_x, val_y)\n",
        "                      ,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_mean_squared_error', patience=2)]\n",
        "                      )\n",
        "  \n",
        "  index = np.where(history.history.get(\"val_mean_squared_error\") == np.min(history.history.get(\"val_mean_squared_error\")))[0][0]\n",
        "  train_mse.append(history.history.get(\"mean_squared_error\")[index])\n",
        "  val_mse.append(history.history.get(\"val_mean_squared_error\")[index])\n",
        "  test_mse.append(current_model.evaluate(test_x, test_y)[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_25 (Dense)            (None, 1024)              3090432   \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 256)               262400    \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,371,393\n",
            "Trainable params: 3,371,393\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 17995.7637 - mean_squared_error: 17995.7637 - val_loss: 12901.1709 - val_mean_squared_error: 12901.1709\n",
            "Epoch 2/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 16581.5762 - mean_squared_error: 16581.5762 - val_loss: 12759.8574 - val_mean_squared_error: 12759.8574\n",
            "Epoch 3/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 16394.5020 - mean_squared_error: 16394.5020 - val_loss: 12750.5557 - val_mean_squared_error: 12750.5557\n",
            "Epoch 4/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 16215.5957 - mean_squared_error: 16215.5957 - val_loss: 12878.1484 - val_mean_squared_error: 12878.1484\n",
            "Epoch 5/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 16094.0449 - mean_squared_error: 16094.0449 - val_loss: 12972.2168 - val_mean_squared_error: 12972.2168\n",
            "144/144 [==============================] - 1s 3ms/step - loss: 13877.8350 - mean_squared_error: 13877.8350\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 2048)              6180864   \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 256)               524544    \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,723,969\n",
            "Trainable params: 6,723,969\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1655/1655 [==============================] - 14s 8ms/step - loss: 17292.6836 - mean_squared_error: 17292.6836 - val_loss: 12786.9238 - val_mean_squared_error: 12786.9238\n",
            "Epoch 2/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 16555.0918 - mean_squared_error: 16555.0918 - val_loss: 12902.9004 - val_mean_squared_error: 12902.9004\n",
            "Epoch 3/200\n",
            "1655/1655 [==============================] - 13s 8ms/step - loss: 16325.7842 - mean_squared_error: 16325.7842 - val_loss: 13270.8213 - val_mean_squared_error: 13270.8213\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 14176.1807 - mean_squared_error: 14176.1807\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_35 (Dense)            (None, 1024)              3090432   \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 128)               131200    \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,232,001\n",
            "Trainable params: 3,232,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 18823.3613 - mean_squared_error: 18823.3613 - val_loss: 13231.8535 - val_mean_squared_error: 13231.8535\n",
            "Epoch 2/200\n",
            "1655/1655 [==============================] - 9s 6ms/step - loss: 16562.7832 - mean_squared_error: 16562.7832 - val_loss: 12760.5664 - val_mean_squared_error: 12760.5664\n",
            "Epoch 3/200\n",
            "1655/1655 [==============================] - 9s 6ms/step - loss: 16367.6309 - mean_squared_error: 16367.6309 - val_loss: 12834.4980 - val_mean_squared_error: 12834.4980\n",
            "Epoch 4/200\n",
            "1655/1655 [==============================] - 9s 6ms/step - loss: 16206.5186 - mean_squared_error: 16206.5186 - val_loss: 12881.2188 - val_mean_squared_error: 12881.2188\n",
            "144/144 [==============================] - 1s 3ms/step - loss: 13732.5020 - mean_squared_error: 13732.5020\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 256)               772608    \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 791,681\n",
            "Trainable params: 791,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1655/1655 [==============================] - 9s 5ms/step - loss: 21204.1914 - mean_squared_error: 21204.1914 - val_loss: 13283.9980 - val_mean_squared_error: 13283.9980\n",
            "Epoch 2/200\n",
            "1655/1655 [==============================] - 8s 5ms/step - loss: 16796.9199 - mean_squared_error: 16796.9199 - val_loss: 12911.2998 - val_mean_squared_error: 12911.2998\n",
            "Epoch 3/200\n",
            "1655/1655 [==============================] - 8s 5ms/step - loss: 16622.3301 - mean_squared_error: 16622.3301 - val_loss: 12871.8145 - val_mean_squared_error: 12871.8145\n",
            "Epoch 4/200\n",
            "1655/1655 [==============================] - 8s 5ms/step - loss: 16469.6465 - mean_squared_error: 16469.6465 - val_loss: 12772.3418 - val_mean_squared_error: 12772.3418\n",
            "Epoch 5/200\n",
            "1655/1655 [==============================] - 8s 5ms/step - loss: 16358.0000 - mean_squared_error: 16358.0000 - val_loss: 12738.5381 - val_mean_squared_error: 12738.5381\n",
            "Epoch 6/200\n",
            "1655/1655 [==============================] - 8s 5ms/step - loss: 16263.0801 - mean_squared_error: 16263.0801 - val_loss: 12706.0049 - val_mean_squared_error: 12706.0049\n",
            "Epoch 7/200\n",
            "1655/1655 [==============================] - 8s 5ms/step - loss: 16158.5225 - mean_squared_error: 16158.5225 - val_loss: 12734.4229 - val_mean_squared_error: 12734.4229\n",
            "Epoch 8/200\n",
            "1655/1655 [==============================] - 8s 5ms/step - loss: 16067.1035 - mean_squared_error: 16067.1035 - val_loss: 12866.9355 - val_mean_squared_error: 12866.9355\n",
            "144/144 [==============================] - 1s 3ms/step - loss: 13715.7217 - mean_squared_error: 13715.7217\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_45 (Dense)            (None, 1024)              3090432   \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 128)               131200    \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 4)                 260       \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,230,153\n",
            "Trainable params: 3,230,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "1655/1655 [==============================] - 12s 7ms/step - loss: 82105.8984 - mean_squared_error: 82105.8984 - val_loss: 62873.4375 - val_mean_squared_error: 62873.4375\n",
            "Epoch 2/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 81707.9141 - mean_squared_error: 81707.9141 - val_loss: 62546.9219 - val_mean_squared_error: 62546.9219\n",
            "Epoch 3/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 81314.3125 - mean_squared_error: 81314.3125 - val_loss: 62232.2422 - val_mean_squared_error: 62232.2422\n",
            "Epoch 4/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 80923.8906 - mean_squared_error: 80923.8906 - val_loss: 61920.9180 - val_mean_squared_error: 61920.9180\n",
            "Epoch 5/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 80535.9531 - mean_squared_error: 80535.9531 - val_loss: 61618.9883 - val_mean_squared_error: 61618.9883\n",
            "Epoch 6/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 80150.4453 - mean_squared_error: 80150.4453 - val_loss: 61321.8008 - val_mean_squared_error: 61321.8008\n",
            "Epoch 7/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 79766.2266 - mean_squared_error: 79766.2266 - val_loss: 61009.4570 - val_mean_squared_error: 61009.4570\n",
            "Epoch 8/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 79386.2734 - mean_squared_error: 79386.2734 - val_loss: 60695.9688 - val_mean_squared_error: 60695.9688\n",
            "Epoch 9/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 79010.4297 - mean_squared_error: 79010.4297 - val_loss: 60416.0664 - val_mean_squared_error: 60416.0664\n",
            "Epoch 10/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 78635.1328 - mean_squared_error: 78635.1328 - val_loss: 60096.6641 - val_mean_squared_error: 60096.6641\n",
            "Epoch 11/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 78262.0078 - mean_squared_error: 78262.0078 - val_loss: 59849.6445 - val_mean_squared_error: 59849.6445\n",
            "Epoch 12/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 77888.7188 - mean_squared_error: 77888.7188 - val_loss: 59562.4648 - val_mean_squared_error: 59562.4648\n",
            "Epoch 13/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 77520.7500 - mean_squared_error: 77520.7500 - val_loss: 59278.5234 - val_mean_squared_error: 59278.5234\n",
            "Epoch 14/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 77152.4844 - mean_squared_error: 77152.4844 - val_loss: 58996.6641 - val_mean_squared_error: 58996.6641\n",
            "Epoch 15/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 76786.7109 - mean_squared_error: 76786.7109 - val_loss: 58710.3594 - val_mean_squared_error: 58710.3594\n",
            "Epoch 16/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 76421.1641 - mean_squared_error: 76421.1641 - val_loss: 58416.0781 - val_mean_squared_error: 58416.0781\n",
            "Epoch 17/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 76058.4141 - mean_squared_error: 76058.4141 - val_loss: 58135.1406 - val_mean_squared_error: 58135.1406\n",
            "Epoch 18/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 75693.9766 - mean_squared_error: 75693.9766 - val_loss: 57860.2422 - val_mean_squared_error: 57860.2422\n",
            "Epoch 19/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 75329.7422 - mean_squared_error: 75329.7422 - val_loss: 57557.4180 - val_mean_squared_error: 57557.4180\n",
            "Epoch 20/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 74970.4141 - mean_squared_error: 74970.4141 - val_loss: 57285.9180 - val_mean_squared_error: 57285.9180\n",
            "Epoch 21/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 74613.1797 - mean_squared_error: 74613.1797 - val_loss: 57002.4883 - val_mean_squared_error: 57002.4883\n",
            "Epoch 22/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 74259.7031 - mean_squared_error: 74259.7031 - val_loss: 56766.0078 - val_mean_squared_error: 56766.0078\n",
            "Epoch 23/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 73905.3125 - mean_squared_error: 73905.3125 - val_loss: 56446.1875 - val_mean_squared_error: 56446.1875\n",
            "Epoch 24/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 73552.0234 - mean_squared_error: 73552.0234 - val_loss: 56196.8047 - val_mean_squared_error: 56196.8047\n",
            "Epoch 25/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 73202.5781 - mean_squared_error: 73202.5781 - val_loss: 55886.3438 - val_mean_squared_error: 55886.3438\n",
            "Epoch 26/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 72851.5234 - mean_squared_error: 72851.5234 - val_loss: 55647.8438 - val_mean_squared_error: 55647.8438\n",
            "Epoch 27/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 72504.6719 - mean_squared_error: 72504.6719 - val_loss: 55353.5547 - val_mean_squared_error: 55353.5547\n",
            "Epoch 28/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 72157.3047 - mean_squared_error: 72157.3047 - val_loss: 55109.9062 - val_mean_squared_error: 55109.9062\n",
            "Epoch 29/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 71816.1719 - mean_squared_error: 71816.1719 - val_loss: 54850.1680 - val_mean_squared_error: 54850.1680\n",
            "Epoch 30/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 71468.0859 - mean_squared_error: 71468.0859 - val_loss: 54592.7578 - val_mean_squared_error: 54592.7578\n",
            "Epoch 31/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 71133.0859 - mean_squared_error: 71133.0859 - val_loss: 54307.8672 - val_mean_squared_error: 54307.8672\n",
            "Epoch 32/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 70789.1250 - mean_squared_error: 70789.1250 - val_loss: 54053.8320 - val_mean_squared_error: 54053.8320\n",
            "Epoch 33/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 70453.1484 - mean_squared_error: 70453.1484 - val_loss: 53827.0430 - val_mean_squared_error: 53827.0430\n",
            "Epoch 34/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 70118.6406 - mean_squared_error: 70118.6406 - val_loss: 53535.0000 - val_mean_squared_error: 53535.0000\n",
            "Epoch 35/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 69782.3672 - mean_squared_error: 69782.3672 - val_loss: 53253.5000 - val_mean_squared_error: 53253.5000\n",
            "Epoch 36/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 69452.4922 - mean_squared_error: 69452.4922 - val_loss: 53034.0352 - val_mean_squared_error: 53034.0352\n",
            "Epoch 37/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 69123.3203 - mean_squared_error: 69123.3203 - val_loss: 52787.7148 - val_mean_squared_error: 52787.7148\n",
            "Epoch 38/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 68789.0469 - mean_squared_error: 68789.0469 - val_loss: 52515.7891 - val_mean_squared_error: 52515.7891\n",
            "Epoch 39/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 68462.7266 - mean_squared_error: 68462.7266 - val_loss: 52276.7891 - val_mean_squared_error: 52276.7891\n",
            "Epoch 40/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 68135.8281 - mean_squared_error: 68135.8281 - val_loss: 52013.7930 - val_mean_squared_error: 52013.7930\n",
            "Epoch 41/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 67820.3750 - mean_squared_error: 67820.3750 - val_loss: 51801.3984 - val_mean_squared_error: 51801.3984\n",
            "Epoch 42/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 67489.7031 - mean_squared_error: 67489.7031 - val_loss: 51521.6719 - val_mean_squared_error: 51521.6719\n",
            "Epoch 43/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 67171.0469 - mean_squared_error: 67171.0469 - val_loss: 51299.3008 - val_mean_squared_error: 51299.3008\n",
            "Epoch 44/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 66850.5938 - mean_squared_error: 66850.5938 - val_loss: 51029.0781 - val_mean_squared_error: 51029.0781\n",
            "Epoch 45/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 66534.1562 - mean_squared_error: 66534.1562 - val_loss: 50765.2383 - val_mean_squared_error: 50765.2383\n",
            "Epoch 46/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 66215.1641 - mean_squared_error: 66215.1641 - val_loss: 50515.8359 - val_mean_squared_error: 50515.8359\n",
            "Epoch 47/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 65904.0078 - mean_squared_error: 65904.0078 - val_loss: 50324.4531 - val_mean_squared_error: 50324.4531\n",
            "Epoch 48/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 65589.2734 - mean_squared_error: 65589.2734 - val_loss: 50118.5703 - val_mean_squared_error: 50118.5703\n",
            "Epoch 49/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 65278.6992 - mean_squared_error: 65278.6992 - val_loss: 49854.6953 - val_mean_squared_error: 49854.6953\n",
            "Epoch 50/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 64963.5000 - mean_squared_error: 64963.5000 - val_loss: 49620.8281 - val_mean_squared_error: 49620.8281\n",
            "Epoch 51/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 64655.0391 - mean_squared_error: 64655.0391 - val_loss: 49352.0547 - val_mean_squared_error: 49352.0547\n",
            "Epoch 52/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 64346.7617 - mean_squared_error: 64346.7617 - val_loss: 49128.6133 - val_mean_squared_error: 49128.6133\n",
            "Epoch 53/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 64040.0547 - mean_squared_error: 64040.0547 - val_loss: 48862.1797 - val_mean_squared_error: 48862.1797\n",
            "Epoch 54/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 63735.3477 - mean_squared_error: 63735.3477 - val_loss: 48665.7773 - val_mean_squared_error: 48665.7773\n",
            "Epoch 55/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 63433.4375 - mean_squared_error: 63433.4375 - val_loss: 48392.4062 - val_mean_squared_error: 48392.4062\n",
            "Epoch 56/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 63133.2891 - mean_squared_error: 63133.2891 - val_loss: 48217.4492 - val_mean_squared_error: 48217.4492\n",
            "Epoch 57/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 62837.6875 - mean_squared_error: 62837.6875 - val_loss: 47993.3281 - val_mean_squared_error: 47993.3281\n",
            "Epoch 58/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 62533.9336 - mean_squared_error: 62533.9336 - val_loss: 47746.0742 - val_mean_squared_error: 47746.0742\n",
            "Epoch 59/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 62235.1992 - mean_squared_error: 62235.1992 - val_loss: 47533.1914 - val_mean_squared_error: 47533.1914\n",
            "Epoch 60/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 61939.4297 - mean_squared_error: 61939.4297 - val_loss: 47283.8398 - val_mean_squared_error: 47283.8398\n",
            "Epoch 61/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 61659.7266 - mean_squared_error: 61659.7266 - val_loss: 47048.7852 - val_mean_squared_error: 47048.7852\n",
            "Epoch 62/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 61353.7461 - mean_squared_error: 61353.7461 - val_loss: 46827.2734 - val_mean_squared_error: 46827.2734\n",
            "Epoch 63/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 61059.6680 - mean_squared_error: 61059.6680 - val_loss: 46634.3086 - val_mean_squared_error: 46634.3086\n",
            "Epoch 64/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 60773.0703 - mean_squared_error: 60773.0703 - val_loss: 46441.6992 - val_mean_squared_error: 46441.6992\n",
            "Epoch 65/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 60486.7500 - mean_squared_error: 60486.7500 - val_loss: 46217.4180 - val_mean_squared_error: 46217.4180\n",
            "Epoch 66/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 60199.5391 - mean_squared_error: 60199.5391 - val_loss: 46008.1016 - val_mean_squared_error: 46008.1016\n",
            "Epoch 67/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 59908.7812 - mean_squared_error: 59908.7812 - val_loss: 45829.5352 - val_mean_squared_error: 45829.5352\n",
            "Epoch 68/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 59622.0820 - mean_squared_error: 59622.0820 - val_loss: 45558.3945 - val_mean_squared_error: 45558.3945\n",
            "Epoch 69/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 59342.5938 - mean_squared_error: 59342.5938 - val_loss: 45320.2305 - val_mean_squared_error: 45320.2305\n",
            "Epoch 70/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 59064.6680 - mean_squared_error: 59064.6680 - val_loss: 45136.1992 - val_mean_squared_error: 45136.1992\n",
            "Epoch 71/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 58779.9805 - mean_squared_error: 58779.9805 - val_loss: 44938.8125 - val_mean_squared_error: 44938.8125\n",
            "Epoch 72/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 58502.6562 - mean_squared_error: 58502.6562 - val_loss: 44773.0430 - val_mean_squared_error: 44773.0430\n",
            "Epoch 73/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 58214.5938 - mean_squared_error: 58214.5938 - val_loss: 44483.9414 - val_mean_squared_error: 44483.9414\n",
            "Epoch 74/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 57944.1992 - mean_squared_error: 57944.1992 - val_loss: 44330.7812 - val_mean_squared_error: 44330.7812\n",
            "Epoch 75/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 57664.9766 - mean_squared_error: 57664.9766 - val_loss: 44089.9805 - val_mean_squared_error: 44089.9805\n",
            "Epoch 76/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 57392.0039 - mean_squared_error: 57392.0039 - val_loss: 43874.7812 - val_mean_squared_error: 43874.7812\n",
            "Epoch 77/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 57119.6641 - mean_squared_error: 57119.6641 - val_loss: 43685.6875 - val_mean_squared_error: 43685.6875\n",
            "Epoch 78/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 56837.8516 - mean_squared_error: 56837.8516 - val_loss: 43508.2344 - val_mean_squared_error: 43508.2344\n",
            "Epoch 79/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 56578.9062 - mean_squared_error: 56578.9062 - val_loss: 43296.6875 - val_mean_squared_error: 43296.6875\n",
            "Epoch 80/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 56303.0742 - mean_squared_error: 56303.0742 - val_loss: 43061.6250 - val_mean_squared_error: 43061.6250\n",
            "Epoch 81/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 56031.0000 - mean_squared_error: 56031.0000 - val_loss: 42906.8555 - val_mean_squared_error: 42906.8555\n",
            "Epoch 82/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 55766.0273 - mean_squared_error: 55766.0273 - val_loss: 42728.3711 - val_mean_squared_error: 42728.3711\n",
            "Epoch 83/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 55491.2539 - mean_squared_error: 55491.2539 - val_loss: 42489.7383 - val_mean_squared_error: 42489.7383\n",
            "Epoch 84/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 55224.1836 - mean_squared_error: 55224.1836 - val_loss: 42230.7617 - val_mean_squared_error: 42230.7617\n",
            "Epoch 85/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 54968.0938 - mean_squared_error: 54968.0938 - val_loss: 42129.2305 - val_mean_squared_error: 42129.2305\n",
            "Epoch 86/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 54701.7422 - mean_squared_error: 54701.7422 - val_loss: 41891.6094 - val_mean_squared_error: 41891.6094\n",
            "Epoch 87/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 54436.3711 - mean_squared_error: 54436.3711 - val_loss: 41685.6328 - val_mean_squared_error: 41685.6328\n",
            "Epoch 88/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 54168.7969 - mean_squared_error: 54168.7969 - val_loss: 41581.5234 - val_mean_squared_error: 41581.5234\n",
            "Epoch 89/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 53914.8086 - mean_squared_error: 53914.8086 - val_loss: 41385.6953 - val_mean_squared_error: 41385.6953\n",
            "Epoch 90/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 53638.8281 - mean_squared_error: 53638.8281 - val_loss: 41163.2500 - val_mean_squared_error: 41163.2500\n",
            "Epoch 91/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 53382.2031 - mean_squared_error: 53382.2031 - val_loss: 41013.6758 - val_mean_squared_error: 41013.6758\n",
            "Epoch 92/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 53136.6406 - mean_squared_error: 53136.6406 - val_loss: 40787.8516 - val_mean_squared_error: 40787.8516\n",
            "Epoch 93/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 52861.4961 - mean_squared_error: 52861.4961 - val_loss: 40675.8711 - val_mean_squared_error: 40675.8711\n",
            "Epoch 94/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 52618.4336 - mean_squared_error: 52618.4336 - val_loss: 40466.8906 - val_mean_squared_error: 40466.8906\n",
            "Epoch 95/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 52361.7734 - mean_squared_error: 52361.7734 - val_loss: 40233.7656 - val_mean_squared_error: 40233.7656\n",
            "Epoch 96/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 52107.1523 - mean_squared_error: 52107.1523 - val_loss: 40084.8828 - val_mean_squared_error: 40084.8828\n",
            "Epoch 97/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 51861.0273 - mean_squared_error: 51861.0273 - val_loss: 39844.3398 - val_mean_squared_error: 39844.3398\n",
            "Epoch 98/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 51603.4297 - mean_squared_error: 51603.4297 - val_loss: 39632.3555 - val_mean_squared_error: 39632.3555\n",
            "Epoch 99/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 51359.5625 - mean_squared_error: 51359.5625 - val_loss: 39605.4453 - val_mean_squared_error: 39605.4453\n",
            "Epoch 100/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 51113.7852 - mean_squared_error: 51113.7852 - val_loss: 39331.2500 - val_mean_squared_error: 39331.2500\n",
            "Epoch 101/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 50854.1016 - mean_squared_error: 50854.1016 - val_loss: 39174.8477 - val_mean_squared_error: 39174.8477\n",
            "Epoch 102/200\n",
            "1655/1655 [==============================] - 10s 6ms/step - loss: 50614.6875 - mean_squared_error: 50614.6875 - val_loss: 39032.6875 - val_mean_squared_error: 39032.6875\n",
            "Epoch 103/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 50370.5703 - mean_squared_error: 50370.5703 - val_loss: 38790.2383 - val_mean_squared_error: 38790.2383\n",
            "Epoch 104/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 50114.9180 - mean_squared_error: 50114.9180 - val_loss: 38701.4766 - val_mean_squared_error: 38701.4766\n",
            "Epoch 105/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 49886.8242 - mean_squared_error: 49886.8242 - val_loss: 38508.7031 - val_mean_squared_error: 38508.7031\n",
            "Epoch 106/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 49647.9766 - mean_squared_error: 49647.9766 - val_loss: 38291.8555 - val_mean_squared_error: 38291.8555\n",
            "Epoch 107/200\n",
            "1655/1655 [==============================] - 11s 7ms/step - loss: 49400.8281 - mean_squared_error: 49400.8281 - val_loss: 38103.8164 - val_mean_squared_error: 38103.8164\n",
            "Epoch 108/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 49166.7617 - mean_squared_error: 49166.7617 - val_loss: 38002.3789 - val_mean_squared_error: 38002.3789\n",
            "Epoch 109/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 48921.5273 - mean_squared_error: 48921.5273 - val_loss: 37753.4922 - val_mean_squared_error: 37753.4922\n",
            "Epoch 110/200\n",
            "1655/1655 [==============================] - 11s 6ms/step - loss: 48682.5664 - mean_squared_error: 48682.5664 - val_loss: 37599.4531 - val_mean_squared_error: 37599.4531\n",
            "Epoch 111/200\n",
            "1541/1655 [==========================>...] - ETA: 0s - loss: 48510.8438 - mean_squared_error: 48510.8438"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-7b036f82753e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   history = current_model.fit(training_x, training_y ,\n\u001b[1;32m     13\u001b[0m                       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                       \u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                       )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "vehzhy9jMR13",
        "outputId": "3c00f154-f34e-439b-b823-475de821bdd1"
      },
      "source": [
        "pd.DataFrame({\"Nodes\": nodes_4_layers, \"Training\": train_mse, \"Validation\": val_mse, \"Test\": test_mse})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-d636eb74c85c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Nodes\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnodes_4_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Validation\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_mse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN4qxdG4B3If"
      },
      "source": [
        "index = np.where(history.history.get(\"val_mean_squared_error\") == np.min(history.history.get(\"val_mean_squared_error\")))[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2ZXYw1aIwZ3",
        "outputId": "5d9ab5b8-6365-4551-b413-62cf1eff2051"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [43179.3984375, 42484.29296875, 41817.83203125],\n",
              " 'mean_squared_error': [43179.3984375, 42484.29296875, 41817.83203125],\n",
              " 'val_loss': [40902.41015625, 40998.078125, 40924.296875],\n",
              " 'val_mean_squared_error': [40902.41015625, 40998.078125, 40924.296875]}"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vXJInfBCmv2",
        "outputId": "3498ce35-a4bc-4079-90e2-33dda8edab35"
      },
      "source": [
        "history.history\n",
        "print(\"Min Train MSE: \", history.history.get(\"mean_squared_error\")[index])\n",
        "print(\"Min Val MSE: \", history.history.get(\"val_mean_squared_error\")[index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min Train MSE:  43179.3984375\n",
            "Min Val MSE:  40902.41015625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nG-yL9nJ5JO"
      },
      "source": [
        "run_number = []\n",
        "train_mse = []\n",
        "val_mse = []\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCN5ngJDtOwG",
        "outputId": "77b5b1a5-b3da-4fd0-ab6c-9f4778eada2e"
      },
      "source": [
        "%%time\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu',\n",
        "input_shape=(training_x.shape[1],)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 58.5 ms, sys: 18.8 ms, total: 77.3 ms\n",
            "Wall time: 222 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAN3-NhCt7wn"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4)\n",
        "              ,loss=\"mean_squared_error\" # if we set from_logits=True we don not have specify a softmax activation function in the last layer\n",
        "              ,metrics=['mean_squared_error'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNdj1qvttwk2",
        "outputId": "56c983c9-91d8-46cf-ac86-8329e5d337ed"
      },
      "source": [
        "%%time\n",
        "history = model.fit(training_x, training_y ,\n",
        "                    epochs = 10 ,validation_data=(val_x, val_y)\n",
        "                    ,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_mean_squared_error', patience=2)]\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1655/1655 [==============================] - 9s 5ms/step - loss: 70168.0156 - mean_squared_error: 70168.0156 - val_loss: 46662.5039 - val_mean_squared_error: 46662.5039\n",
            "Epoch 2/10\n",
            "1655/1655 [==============================] - 8s 5ms/step - loss: 55944.3398 - mean_squared_error: 55944.3398 - val_loss: 44853.1094 - val_mean_squared_error: 44853.1094\n",
            "Epoch 3/10\n",
            "1655/1655 [==============================] - 8s 5ms/step - loss: 52940.1172 - mean_squared_error: 52940.1172 - val_loss: 42956.9102 - val_mean_squared_error: 42956.9102\n",
            "Epoch 4/10\n",
            "1655/1655 [==============================] - 8s 5ms/step - loss: 50077.3320 - mean_squared_error: 50077.3320 - val_loss: 41828.2031 - val_mean_squared_error: 41828.2031\n",
            "Epoch 5/10\n",
            "1655/1655 [==============================] - 7s 4ms/step - loss: 48196.2109 - mean_squared_error: 48196.2109 - val_loss: 41485.2227 - val_mean_squared_error: 41485.2227\n",
            "Epoch 6/10\n",
            "1655/1655 [==============================] - 8s 5ms/step - loss: 46986.4336 - mean_squared_error: 46986.4336 - val_loss: 41285.1289 - val_mean_squared_error: 41285.1289\n",
            "Epoch 7/10\n",
            "1655/1655 [==============================] - 7s 5ms/step - loss: 45989.0312 - mean_squared_error: 45989.0312 - val_loss: 41141.9609 - val_mean_squared_error: 41141.9609\n",
            "Epoch 8/10\n",
            "1655/1655 [==============================] - 8s 5ms/step - loss: 45071.3633 - mean_squared_error: 45071.3633 - val_loss: 41000.3984 - val_mean_squared_error: 41000.3984\n",
            "Epoch 9/10\n",
            "1655/1655 [==============================] - 8s 5ms/step - loss: 44187.3672 - mean_squared_error: 44187.3672 - val_loss: 40897.6641 - val_mean_squared_error: 40897.6641\n",
            "Epoch 10/10\n",
            "1655/1655 [==============================] - 7s 4ms/step - loss: 43322.1055 - mean_squared_error: 43322.1055 - val_loss: 40856.0625 - val_mean_squared_error: 40856.0625\n",
            "CPU times: user 1min 35s, sys: 8.09 s, total: 1min 43s\n",
            "Wall time: 1min 18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvW4qisAEKoQ",
        "outputId": "c7cd3faf-e64a-40bc-ca3d-4d898b638fc0"
      },
      "source": [
        "print(\"MSE: \", model.evaluate(test_x, test_y)[1], \"\\nRMSE: \",  np.sqrt(model.evaluate(test_x, test_y)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144/144 [==============================] - 0s 2ms/step - loss: 43641.8633 - mean_squared_error: 43641.8633\n",
            "144/144 [==============================] - 0s 3ms/step - loss: 43641.8633 - mean_squared_error: 43641.8633\n",
            "MSE:  43641.86328125 \n",
            "RMSE:  208.90635050483746\n",
            "144/144 [==============================] - 0s 3ms/step - loss: 43641.8633 - mean_squared_error: 43641.8633\n",
            "RMSE:  208.90635050483746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VPbUEAbIOFd",
        "outputId": "06dfa26b-5c2b-4ac4-c9f9-560829cb7a04"
      },
      "source": [
        "5 + 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juE7ESxpssay"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}